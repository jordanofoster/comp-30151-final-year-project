# COMP30151: Project Report - Jordan Foster (N0913799)

## i. Abstract

## ii. Acknowledgements

## iii. Table of Contents

[TOC]

## iv. List of Figures and Tables

## 1 Introduction
<!-- 
Select an area of knowledge for investigation and identify an existing method(s), technique(s), algorithm(s), or system(s) suitable for improvement. Plan, and therefore timetable, a program of research and development, as laid out below. 
-->

### 1.1 Research into existing solutions

### 1.2 Plan

## 2 Context
<!-- 
This should include a literature review in order to detail the State-of-the-Art in the field and the main areas for improvement/further research and determine the LIMITATIONS of the existing method(s), technique(s) or algorithm(s), system(s) (hardware, software, database, etc). These limitations may be in areas or customers currently using the technology as well as in the current functionality of the technology. 
-->

### 2.1 Current State

#### 2.1.1 Current uses of the DMS concept

By the historical nature of DMS systems being used to deterr and intimidate, we must consider the state of their usage in both a protective and aggressive context, to understand the context in which our tool might be used.

##### 2.1.1.1 Uses of the DMS concept as a defensive measure (*'fail-safe/secure' systems*)

We will make the distinct definition that a *fail-safe* system is one that protects the user from a given threat by responding accordingly in a way that *neutralises the impacts of a realised risk. to the operator, the environment, or others.* A *fail-secure* system is one that protects *access* to a resource, building or area in the event of it being triggered, rather than protection of envrionments or person(s).

###### 2.1.1.1.1 Vigilance Monitoring Devices (VMDs)

The typical implementation of a DMS as a failsafe is in railway systems with the use of a *Vigilance Monitoring Device* (VMD) - this is a version of the DMS that *triggers by default* and thus requires consistent interruption by the user. The intent is to not only check for incapacitation of the driver, but also to recognize a low enough level of attention to cause risk. The efficacy of this method of 'repeated distraction' has been long considered ineffectual for this latter purpose within academic literature, however - one historical chapter of a book on vigilance (Fruhstorfer et al., 1977) hypothesizes and subsequently proves that these vigilance assurance processes are able to be performed in the very 'low-vigilance' scenarios they purport to protect against, due to subconscious proceduralization.

Despite this, the concept of using the Dead Man's Switch to check for vigilance is sound, even with the flaws in the medium itself - perhaps a system that changes to make proceduralization difficult could be used, or - as used by the authors themselves - monitoring of neuropsychological indicators of low vigilance states could be done as an alternative (in a future where the technology can be modified for use outside of a lab setting).

###### 2.1.1.1.2 'Kill-cords'

Another common use of the DMS concept is in the use of 'kill cords' in vehicles which are attached to the user; if the user falls off the vehicle or otherwise has it run away from them, the cord is pulled and a circuit is shorted, cutting the engine off (and possibly hitting the breaks). One example of this is explored in a journal article (Boyles et al., 1979) on the use of snowmobiles in the Antarctic. The system itself is simple and mechanical, utilising a 3.5mm headphone jack with a paracord drilled into it; when the jack is inserted the contacts that cause the ignition to short are kept apart; when the cord is pulled, the jack exits and the short reoccurs. Whereas the absence of change indicates a trigger scenario in the prototypical context, in this case it must be 'signalled' that the operator is incapacitated through active 'pulling' of the cord.

Implementing the DMS this way leaves little room for errors of an electronic or computational nature, increasing reliability. However the possibility of wear must still be considered in these instances - with repeated usage the 'grip strength' of the jack itself will lessen, which could result in a dangerous situation where the ignition is unexpectedly shorted resulting in an incident.

The 'kill-cord' implementation is the primary context in which the DMS has been applied to the computing space, as a form of physical security to ensure the confidentiality of information in the event of separation of the user from the computing device. Actual hardware has been produced for this purpose, as seen in the *BusKill* software, which either locks the screen or shuts down the device (Anon., 2023) when a specially designed USB cable with a magnetic breakaway is removed. Another implementation that uses generic USB devices is *hephaest0s'* USBKill (2023), which can be configured to run a user-written procedure when a whitelisted device is *removed* from the system. The LiveOS Linux distribution TAILS also contains a 'kill-cord' in the form of a memory erasure procedure that triggers when the USB or DVD running the OS is removed (Anon., 2023).

The unfortunate reality of such tools in a computing context, however, is that they are often used by cybercriminals. TAILS itself states that it is intended for use by *anyone* that is vulnerable against a stronger adversary - such as activists, whistleblowers, journalists and those suffering abuse - but this same dynamic is present between law enforcement and criminals, and this must be acknowledged (see Section 2.1.1.2). Such systems that use the OS to run antiforensic measures also implicitly trust it, meaning that the efficacy of such solutions depends entirely on the functionality of underlying hardware and firmware, and the assumption that the enacting OS is not compromised such that a triggering of the countermeasure or its realisation thereof is blocked.

###### 2.1.1.1.3 Stop mechanisms for machinery and tools alongside mobility and rehabilitation

The DMS concept is generally known as a 'deadman switch' in this area; one example is the use of on operating valve for blast cleaning nozzles that must be held open during use - this is mandated by OSHA, as initially defined in section 1910.244(b) and later explicitly clarified as a "dead-man" control by a subsequent standards interpretation by the *Directorate of Enforcement Programs* (Fairfax, 2000).

An example of the DMS in an actual design is seen through the use of an *Active Constraint Robot* (ACROBOT) for the purposes of performing knee surgery with a rotary cutter (Davies et al., 1997). Within the paper, it is seen that the operating surgeon must continually depress a force sensor while operating the device. This, in combination with the surgeon only being allowed to backdrive the mechanism within certain regions, helps improve the safety of the device - while still allowing for more complex procedures than those allowed by passive powered robots and unpowered systems.

<!-- picture here. -->

Stop mechanisms also see usage in mobility & rehabilitation systems. One open electric network standard for wheelchairs, M3S (Linmann S., 1996), uses a dead man's switch associated with a joystick that activates *any time* it returns to a netural position; something that may be quite common when powering an electric wheelchair. The system takes care to allow for delay so that components with inertia such as motors may stop smoothly, and the author particularly notes the improved safety of 'failure-by-default' DMS systems compared to those that require action that may be difficult for disabled persons to perform in a timely manner.

*note: expand on limitations.*

###### 2.1.1.1.4 'Smart' systems that trigger based on *proxies* of an operator's input or intent

Due to its electromechanical origin, most DMS systems work under the assumption that a human operator always has their finger on the 'pulse' of the system - be it via a vigilance device, kill-cord, or a button, lever or pedal that must be continually 'pressed' during usage. This assumption works well for situations where the interface between operator and machine is direct and fixed, and the outcome of deactivation is a safe one in all possible failure states.

This naturally begins to fall apart in complex enviromnents and systems: metrics for what constitutes a 'dead-man' situation may be unclear; there may be significant latency in operator input and, most seriously, there may be many failure states - some unpredictable; the 'optimal response' may not always be the same on that basis. One context where this is the case is with driving. Vehicles are sometimes intentionally given no input, and since danger situations are often defined by environment - 'other drivers' - failure states are unpredictable at best; even in internal systems failures, simply cutting power to the engine or forcing the breaks on is not the best situation (such as if it would cause a pile-up).

The primary solution played about with in such cases is to make the DMS 'smarter' - more complex - than typical devices which shy away from complexity out of reliability concerns. Regarding driving specifically, one prototype testbed (Ahsan et al., 2012) operates in three components; an *image processing* module that uses computer vision to assess the orientation and speed of the vehicle, passed onto the *control unit* - which determines proper action - and then an interfacing unit that converts intent to outome via traditional controls. In effect, this implementation could almost be considered a form of 'robo-operator' in that it can act as a secondary driver in the instance that the primary driver is incapacitated (even if its actions are just to pull over in the paper cited); this is not too dissimilar to the 'co-piloting' concept as used when learning to drive - where the instructor can take control - and in aviation systems to accomodate for fatigue. The primary limitation of this method is that proxies can often allow for false positives under the guise of 'better safe than sorry' - so the strength of any response must be accordingly measured to allow for correction in such cases.

###### 2.1.1.1.5 Systems that trigger *without operator involvement* (*'watchdogs'*, *'heartbeats'* and *fault detection*)

Some fail-safe systems are self-triggered such that an action or lack thereof from an operator is not part of the failure state (such as component failures). One example of this is the *watchdog timer*, which is a 'failure-by-default' system that continually counts down towards a fail-safe action (such as power cycling) unless it is 'kicked' (restarted) continually - something also known as a *'heartbeat' signal*.

Not all watchdog systems immediately shut down the system upon inital timer expiry, however - 'multi-stage' systems have early watchdog expiries trigger a non-critical response (such as a corrective action) and then start the next timer in line. Each stage in such a system results in increasingly drastic action upon expiry, with the final stage tending to result in a complete system reset. Given that some failure events are the culmination of several lesser events going unchecked and cascading, such an implementation allows for a measured 'scale' of responses so that events that the system can recover from do not result in an excessive 'correction' (system reset or shutdown). Some other systems, in the typical 'fail-safe' context of engineering, detect faults and react accordingly in a manner that feels a bit more akin to the concept of the 'kill-cord'.

Often such systems that exclude the operator are explicitly considered to *not* be a 'Dead Man's Switch', on the basis that there is no 'man' involved. This makes sense, but the distinction between a human and 'robotic' operator in the context of computer systems is blurry - automation software exists that allows actions to be programmed exactly as a human would do so, and the introduction of machine learning and AI technologies further blurs this distinction as devices gain abilities that, abstracted, were previously assumed to be entirely human (such as visual identification, 'reasoning' and 'creativity'). Combine this with the layers of APIs, frameworks, libraries and other scaffolding that human-computer interfacing is built upon, and there are many areas where the 'signal' to stop or absence thereof (in the case of a 'fail-by-default' system that requires heartbeats) can be lost via system bugs or failures between the 'sender' (operator) and 'receiver' (payload). Thus, digital applications of DMSs must by necessity consider and implement such internal checks and balances to ensure reliability.

*note: limitations?*

##### 2.1.1.2 Uses of the DMS concept as an coercive measure (i.e., *'fail-deadly' systems*)

The term 'fail-deadly' is classically - in a military sense - used to refer to a policy or system that results in automatic and severe consequences for an adversary that commits to an attack or otherwise proactive action against the user, typically in the form of damages. It can functionally be considered the inverse of the 'fail-safe' or 'fail-secure' concept, where the DMS itself is used to *realise* a risk rather than prevent it. Fail-deadly systems typically operate upon deterrence theory, where the *threat* of consequence is enough to prevent an undesired outcome (often - but *not exclusively* - against an 'other'); but there is nothing precluding the possibility of such a system being used as a basis for *compellence* instead - where the projected threat of force an unactivated 'fail-deadly' DMS provides can be used to encourage a desired action. To whit, in the context of the 'carrot-and-stick' metaphor, fail-deadly systems threaten to be the stick that is swung.

However we must also consider that sometimes, the protection against a risk being realised (the concept of the 'fail-safe') in itself can also act as a form of deterrence against an adversary (such as in the case of anti-forensics, where careless action could ruin a case before it even begins). Such risk can be used to compell others to perform actions under threat of intentional triggering of the fail-safe, meaning that effectively both 'types' of DMS can be used aggressively.

As such, this section will cover **both** the uses of fail-safe and fail-deadly systems for the purposes of coercion; it is not a use-case considered explicitly *ethical* in any case - at best it can be considered benign if self-targeted to force an undesired but beneficial behaviour (such as exercise), and at worst it can be considered blunty *unethical* - but the flexibility of DMSs to be used in such a sense means they must be considered at minimum for a complete moral and ethical analysis of potenial usecases.

Due to the nature of 'fail-deadly' systems being used for specific purposes during isolated incidents, much of this section will be a series of individual case studies, rather than review of established 'concepts' and use-cases as with fail-safe systems.

###### 2.1.1.2.1 Uses of 'fail-deadly' systems within deterrence theory

<!-- Massive Retaliation/Mutually Assured Destruction, Launch on Warning 
also see blackmail, assange/snowden
-->
The typical example of a fail-deadly system being used for deterrence purposes is the military doctrine of *Mutually Assurred Destruction* (MAD); Wherein a nation-state with nuclear second-strike capability can theoretically deter a rational agent with the same capacity from attacking them through the threat of apocalyptic outcome. It could be argued that much of modern political theory and action is only possible due to the chilling effect of such doctrine, but this is not foolproof; the doctrine assumes all agents are rational - an area in which humans are falliable - and even assuming perfect rationality, the model of MAD is such that actors are incentivised neither to initiate a conflict *or* disarm themselves; something that can easily lead to lockstep.

It is not unrealistic to say that the social and political dynamics that undermine the validity of such concepts are complex enough to be outside of the scope of this report. Indeed, some nation states use second-strike procedures that would entirely be digital if not for the requirement of senior approval, and this in and of itself has lead to nuclear close calls that have only been prevented due to human intervention and doubt (See Wikipedia, 2023). The 'rationality' of actually firing back once confirmed that a nuclear armament is imminent is difficult to determine as at such a point the underlying 'pre-war' state has been discarded by a theoretically irrational action (firing at all).

However the concept of fail-deadly systems as a use of deterrence does not necessarily have to be of stakes so high as to cause apocalypse; the concept could also be applied in peacetime to ensure things like the maintenance of economic ties through a 'mutually assurred recession'. Such concepts are of debatable ethics however, and the use of a digital system capable of false positives for such a thing could read as reckless at best.

###### 2.1.1.2.2 Uses of 'fail-deadly' systems as a means of compellance

<!-- Beslan siege? Bill Rothstein and Marjorie Diehl Armstrong 
the concept of 'nuclear peace', where nuclear deterrence has been used to
compel adversaries to take different courses of action
(primarily a politics thing...)
-->
The use of MAD (see Section 2.1.1.2.2) oddly enough leads credence for some to the concept of 'nuclear peace', wherein the threat of escalation allows all parties to be more amenable to methods of resolving conflicts that do not require the use of force. This, like the concept of MAD itself, is of questionable stability, however - we already see in the modern day that the threat of nuclear destruction does not prevent war and escalation in and of itself, and often just results in proxy conflicts instead surrounding states without nuclear capability themselves.

The underlying idea itself here is that an actor capable of ensuring retaliation for being 'attacked' subsequently can use said leverage to perform actions that would, normally, have resulted in noncompliance or an attack in the first place. This naturally assumes that the person being compelled cares about the consequences for noncompliance in the first place, and that no action the compellee is dictated to do by the compellant is deemed of *worse* consequence than the punishment for non-compliance in the first place. This is a complex - daresay impossible - risk for the compellant to calculate accurately, as it is dependant on the entirety of the compellee's character; their values, morals, financial situation, social class/status, beliefs and society all factor into whether such a gambit pays off. Obtaining perfect information on this is virtually impossible, since people can act contrary to what factors would suggest, and do not easily convey thoughts.

###### 2.1.1.2.3 Uses of 'fail-deadly' systems on the self or consenting other

<!-- Commitment devices, social contracts, etc. -->
This is the primary form of 'fail-deadly' application that is applied in morally benign and/or acceptable contexts; a person desiring to push themselves towards an action that is helpful long-term but painful in the short-term may lock themselves into a 'contract' to compell them towards an action that is ultimately good for them, or to prevent a self-sabotaging act; the latter being classically known as 'akrasia'. In the context of behavioural psychology, mechanisms that prevent akrasia are known as 'commitment devices'.

Commitment devices encompass a wide range of strategies, but leverage the concept of reward and punishment as a driving force. There are primarily two approaches; removing or reducing the possibility for unwanted acts (deterrence), or threatening consequence for failure to perform an action (compellance). The latter, being 'active', is the closest to the DMS concept; contemporary deterrence measures are often passive (e.g., locking away junk food) and not reactive, such as seen with the kSafe (2023), which locks items away on a timer.

Commitment devices that are reactive ('compellant') in nature tend to be on either side of the 'carrot-and-stick' divide. The concept of gamification (and by extension, persuasive design) focuses heavily on the idea of rewards ('carrots') for performing desired behaviour, and is prevalent across many industries and areas such as education, crowdsourcing, health and gambling - all with varying morality, on the basis that aspects of human psychological behaviour can be 'hacked' to steer someone towards a different outcome. Thus, the line between assistance and coercion in such cases is a thin one - if the user and provider/designer's desired outcomes do not align to the same 'optimal' path, these systems necessarily stray from ethicality by sabotaging the user, potentially in a way that remains undetected if the user is still enjoying themselves.

Far more transparent are services and tools that act as the 'stick' - in the typical 'fail-deadly' sense - though this transparency makes them less likely to see uptake. Providers such as StickK and Beeminder have users pledge to a goal or habit, where failing to meet requirements results in a financial penalty. Some conflict of interest is unfortunately inherent, as the provider seems to profit on failure of the user. Non-financial punishments may fare better, but are often bespoke, such as sites that delete everything written if nothing is typed in a given period, to overcome writer's block - the integration of such ideas with the DMS concept entirely could produce interesting outcomes. The introduction of a human referee in such cases acts to enforce commitments, though to be ethical the user must initially consent to the commitment and have options for potential flexibility (such as in the case of an emergency).

Most current solutions on the market tend to target a very specific 'area' of commitment that needs a solution. As stated before, the kSafe entirely focuses upon deterring actions that are exclusively performed through an item for that purpose - for example, locking away items such as games controllers or food. Handling less tangible 'actions' or those that are tied to objects that see frequent use in general life (such as the computer) is more difficult. Digital services like StickK are limited to what they can observe, and as such often use analogue means of accountability (like referees) instead, which (as an effective employee of the service) are expensive; as such most solutions in this space are for a bespoke purpose and are inflexible to personal minutiae.

The use of a configurable DMS for this purpose may allow for similar control over 'digital' akrasia (such as procrastination on the web) as is possible in the physical world, as most contemporary tools must grant themselves levels of control significant enough to be a security concern. For 'stick' based approaches, programmatic means of determining progress or goal completion seem to be preferred.

#### 2.1.2 State of understanding regarding DV and its countermeasures

##### 2.1.2.1 Patterns of abuse

An early concept that focused on the context of abuse was a 1979 theory by Lenore Walker known as the *Cycle of Abuse* (see Fisher 2010, pp. 256-261), which suggests that domestic violence incidents occur on a cyclical basis within established relationships: tension builds to a head resulting in an incident, which is then followed by reconcilliation efforts by the abuser which results in a presumed amnesic phase of calm.

There are suspicions (again, see fisher 2010, pp. 256-261) that this model is inaccurate; Fisher claims '1,500' women were surveyed - Walker (1980) herself contradicts this in the original work, stating "over 120 detailed stories" and that she "[had] listened to fragments of over 300 more[...]" - and that responses were anecdotal in nature; Fisher also notes that some critics (notably, not directly cited) point out that many women did not necessarily perceive themselves as victims of abuse. Indeed, in a later work Walker (1980) notes that those surveyed self-volunteered to try and identify whether they *were* being abused and that "[it was] difficult to distinguish between those women living in unfuflilling and unhappy marriages and those in battering relationships".

In addition, questioning appeared to be unstructured, as Walker states that when "[she] began, [she] did not know what questions to ask, so [she] let [the women] tell their stories in their own ways". A footnote in a later work (Walker 1989) clarifies that her questioning up to that point - 1989 - was a mix of "forced-choice and open-ended questions in a systematic format", though whether this tracks with her original work is unclear; regardless this questioning "later became the model for the Battered Woman Syndrome Questionnaire [used in forensic evaluation]", so it would likely have been decently regarded for the time period as a method for expert testimony.

The lack of pinnable methodology here unfortunately hinders the reproducibility of Walker's findings though, and thus the ability to ascertain the validity of her theory; given that within Walker 1980 she outright discourages the use of her study as a dataset from which to generalize trends (and the prior evidence supporting as such), it seems unwise to base threat modelling and design decisions entirely upon it - though it may be useful as an aid to thought.

##### 2.1.2.2 Cultural and Social factors

###### 2.1.2.2.1 Intergenerational Violence

Adjacent to Lenore's theory of *intrapersonal* violence (see section 2.1.2.1.1) is the concept of *intergenerational* violence, which has been similarly referred to as the *'Cycle of Violence'*; summarily, the idea that persons abused in youth - by family or others within society - have a tendency to become abusive themselves.

One chapter (Widom, C.S. and Wilson, H.W, 2015) of a larger summative work on the state of violence and mental health (Lindert J. and Levav I., 2015) states that the groundwork is based on the context of *social learning theory* (that children learn behaviours through imitation of higher-status 'others') and that children who are rejected in their attempts to bond with their caretaker - something necessary for well-adjusted outcomes, according to *Attachment Theory* - tend to view ambiguous social situations later in life with a bias towards hostility, and have impeded ability to handle stress and emotion, either through an overtly aggressive (abusive) response or insufficient empathy (neglect).

This is notable for our design, because such behaviours may propagate across communities according to *social contagion theory* (see Christakis and Fowler, 2013); for example, given that LGBTQ+ people are more susceptible to abuse (McGregor 2023), it might be theorized that could have negative effects on hypothetically supportive communities too - as one study on DV within LGB communities (Bornstein et al., 2006) indicates that support was difficult to get due to the deep social integration of the abusers with the LGBTQ+ community at large. Thus, we have to consider the possibility that usage of a dead man's switch to communicate with external confidants may be ineffective if the supporting community also carries some of these traits - which they may, if they themselves are survivors.

In the same breath, it is crucial to state that within the same work it is noted that "most individuals *do not* become violent offenders as adults", citing a study that only 1 in 5 were *arrested* for violence as adults. Considering the phrasing and that the authors' only citation for that claim - "Maxfield and Widom (1996)" - is at least partially self-referential, skepticism may be required, but this lack of connection of cause and effect is at least noteworthy and tarring both a supportive survivor and abuser with the same brush of 'prone to behavioural corruption' on the basis of 'abused people abuse people' could very well be unhelpful at best and plays right into isolative strategies of control at worst. Nonetheless, the possibility should be considered when modelling threat to realise the likelihood and consequences of such a risk being realised.

However some critiques must be made before blindly applying it to DV; it should be noted that using arrests as a proxy for violent action if anything would result in underreporting, and that the phrasing implies the encompassment of *any violence, public or private*. Many cases of domestic abuse *do not* result in appropriate outcomes for the assailant due to the 'covert' nature of non-physical abuse - see Stark (2012, p.205) - so perhaps this indicates low rates of transferrence for *delinquent* (rather than domestically abusive) tendencies.

Behavioural genetics are also regarded, and the idea that maltreatment could result in gene-environment interactions that predispose a person to violence is considered. However it should be noted that particularly in the context of *complex traits* - traits that do not adhere to the *Mendelian* (single-gene, 'dominant-recessive') model of inheritance - non-replication is a concern (Winham and Biernacka, 2013). Studies related to the gene associated with this potential (MAOA) is noted by Winham and Biernacka to have been criticised for replication issues also, though they also cite consistently supportive findings in recent times.

The authors of the chapter on *intergenerational violence* (Widom, specifically), in their discussion of MAOA, cite further studies that indicate the efficacy of the MAOA gene differs based on ethnicity, but these are self-referential also. Given this, alongside the lack of clear consensus regarding the weighting of MAOA and its activation on perpetuation of violence, and past issues with replication, genetic factors that may affect the trustworthiness of any confidant(s) with which the DMS is trusted in context of deployment will not be considered further.

###### 2.1.2.2.2 Societal indifference and support for domestic violence

In societies that place a high value on honor and values that facilitate its maintenance and improvement, domestic violence is generally viewed as a means for a man to reclaim honor lost as a result of spousal infidelity, and women are expected to maintain loyalty in the face of this abuse (Vandello and Cohen, 2003). In some cultures, domestic violence appears so accepted to be considered necessary even by those vulnerable to it, such as other women, as seen in a meta-analysis on the issue in Ethiopia (Guracho and Bifftu 2018) - wherein perceived transgressions including incompetence, lack of sexuality, lack of loyalty and even suspicion of infidelity are all considered beatable offences by female respondants to the point of considering abusive punishment as a form of affection (perhaps as a manifestation of a trauma bond). Contributing to such culture, even in societies that consider the act distasteful, is the occasional belief that DV is a private family matter - perhaps comparable to alcoholicism or a gambling addiction - and that the state bringing such matters into the sunlight and making attempts to solve the problem is a violation of rights and privacy (Hajjar 2004, p.10; Bailey 2012).

In combination with previous review of intergenerational violence, the significance of culturally and physically external safe-spaces - such as those provided by information technologies - appear to be high to victims in these situations; as when localized structures of power fail to recognize the issue, external cultural influences act as the only support. This is something easily seen within Western society as LGBTQ+ individuals in communities where coming out would be dangerous and/or otherwise unadvisable seek and benefit from support online (Craig and McInroy 2014). Ensuring the availability of external support in a covert manner is crucial - something that a DMS implementation may be able to assist with.

##### 2.1.2.3 Legal and Enforcement Factors

###### 2.1.2.3.1 Legislation that perpetuates abuse

Law that perpetuates the domestic violence issue is primarily that which is tied with marriage; restrictive law regarding the rights of residence for immigrants married to citizens can act as an unintentional power asymmetry between the abuser - a citizen - and the victim, who is not and therefore loses the right to live in the country if they choose to leave a relationship (Narayan 1995). More explicitly, where law and some subsets of pious belief are intertwined, the rights of a wife within the marriage are considered lesser than the rights of the husband, as can be seen in Egypt, which has a separate divorce process for women and man that advantages the latter (*Human Rights Watch*, 2004).

Law in any country can be modelled as being at least partially based on culture such as tradition under the German historical-school of law (Mautner 2011), but sometimes long-standing law can be internalized by citizenry as a form of morality in and of itself on the basis that breaking the law is seen as immoral - see the *procedural justice model of compliance*, as discussed by Jackson et al. (2012) - and this may propagate outside of the domain of the state that enacts them. Law defines and denies rights, and this can cause confusion when crimes are committed by persons that are considered either acceptable or unprosecutable in their countries of birth; indeed, in some U.S. DV cases a 'cultural defence' has been successfully used to limit sentencing in such instances on the basis of misunderstanding (Gallin 1993), which could be argued to undermine the rights of the victim in preference of the abuser.

###### 2.1.2.3.2 Difficulty of Prosecution

Perhaps as a *consequence* of minimization of violence and its intergenerational nature (see section 2.1.2.2), some survivors of DV do not wish to be involved in the prosecution process or to even have their abuser prosecuted to maintain a sense of privacy and personhood, as is shown by Bailey (2012) - who argues that this desire should be respected by U.S. authorities. Of particular interest is her point that individualist privacy and personhood are strongly held values within American culture, and the subsequent implicit suggestion that these values should take priority over that of justice and 'greater good' (if one views DV left unpunished a *societal* harm).

Although the angle of protest is different here - being sympathetic to the survivor rather than the abuser - the fundamental argument that the state should not interfere in matters of the survivor is unfortunately adjacent to the idea that the state should not intervene in 'family matters' or 'matters of the faith' as seen in other cultures, as touched upon in section 2.1.2.2. It is outside of the scope of this report and the education of the author to provide extensive commentary on this complexity, but ultimately this shows that each state must balance minimization of DV incidents through prosecution while not causing further psychological damages to the survivor; the relative importances of which will depend on societal values.

This matter is worsened by historical stigma against mental health (Zartaloudi and Madianos 2009) and callousness regarding DV incidents (see section 2.1.2.2.2); meaning the problem cannot simply be 'quashed under the gavel' - so to speak - and requires multifaceted action. In the short-term, perhaps the best thing judges and juries can do is educate themselves on consequences of past decisions to the survivor, and how that might affect their own.

###### 2.1.2.3.3 Law Enforcement

Law enforcement often act as first responders to domestic violence situations, and for this role they are not particularly suited. Fulambarker (2020) uses the concept of role theory applied to a study of eight participatory officers across 6 different U.S. departments consisting of "semi-structured", one-hour interviews to identify a few key problems with DV situations that officers face.

Amongst these are the lack of clarity regarding role and the inherent ambiguity of situations - particularly the pressures of handling dangerous situations in both the classical, preventionist sense - that aims to limit immediate consequence via possibly drastic action - and how this contrasts with the slower, perhaps more 'considerate' approach required by a social worker. In combination with this, the perceived lack of 'social worker'-type skills and lack of ability to reach proper resolutions to domestic violence scenarios contributes to what Fulambarker notes as 'role overload' for officers, where the demand of their role(s) leads to adverse effects; this could potentially make them worse at responding to future situations.

Historical policy (James 1994) has been for officers to avoid arrests if able due to tendencies for the victim to wish to drop charges - something still in place today, as previously shown (Bailey 2012) - and take more of a peacemaker role that may have contributed to the 'dual-role' mindset that officers appeared to show overwhelm towards in Fulambarker's study. James also notes that as DV has moved from a misdemeanor to a criminal charge in the U.S., so too have states moved towards 'no-drop' prosecution policy, and allowing arrests based on probable cause. The resultant effect of this is that modern law expects officers to treat this as a societal issue - equivalent to assault and battery - while implicitly also having them take on a caretaker role. While it is perfectly expected that an officer should be capable of working in both an arresting and peacekeeping capacity, the complexity of domestic incidents can lead to incorrect judgements and actions that worsen the situation.

Danis (2003) notes that the consensus on arrests being an effective method of preventing revictimization is mixed, and that it can have unintended consequences, such as perhaps *increasing* the risk of future retaliation from the abuser in the case of on-scene arrests (as opposed to warrants). Furthermore, it is noted that having an officer take the role may in some cases reduce the victim's desire to seek help through intervention, including those within communities that distrust the police and unofficial migrants that may fear deportation if 'the law' gets involved (also see section 2.1.2.3.1). Danis also notes that sometimes officers use family and neighbours as 'interpreters' of a situation to compensate for their own lack of knowledge, which can embarass victims and enrage abusers.

To summarize, the potential for violence when being the first responder to a DV situation, combined with a lack of specialist training and prior skepticism of police can result in a situation that makes it difficult for officers to handle situations well, and encourages victims to not 'raise the alarm' for fear that things become worse.

Perhaps a more generalist sign that officers may not always be the best 'first repsonders' to DV incidents is the idea that police families are more prone to having domestic violence incidents themselves; Blumenstein (2009), in a survey of a convenience sample of officers within departments that had a survey distribution mechanism within Tampa, Florida, assessed 90 respondants with questions on the *Revised Conflict Tactics Scale* (CTS2) to determine whether alignment to values shown in traditional policing subculture correlates with engagement with abuse. Blumenstein found that within this dataset, there was a correlation between alignment and likelihood of engagement in *psychological abuse* but *not* physical violence; however this may be inaccurate due to geography (a singular area), the possibility of self-censorship on the respondants' part, and a primarily caucasian male dataset due to the sampling method.

Blumenstein concludes that perhaps the types of people that *enter* police roles are perhaps of a disposition more likely to result in abuse, and that viewing the issue through the lens of 'police culture' might be the wrong approach, although more studies are needed to confirm or deny as such. As if to demonstrate the lack of consensus regarding causes for this issue however, an earlier paper (Aamodt et al., 1998)'s meta-analysis on the personalities of law-enforcement using the *Minnesota Multiphasic Personality Inventory* (MMPI) seems to indicate there is no association between the scales identified in "police personalities" and those present in the "batterer personality" of the MMPI. The entirety of the police demographic took the test for a reason (employment) that indicates voluntary participation compared to batterers however, and the reason thereof once again may have affected responses according to 'expected conduct' (a person with abusive tendences is not, theoretically, a good candidate for police work).

The resultant conclusion that can be made is that it is difficult to analyse for any personality-based indicators that create a 'direct-link' between officer and abuser, besides the correlative aspect, as cited in Blumenstein and Aamodt et al.'s work (see Sgambelluri, 2000; Reming, 1998 respectively). Regardless of the actual truth of the matter, even a 'folklore truth' that this might be the case can make victims untrusting of police on top of any potential existing cultural and class-based influences that might already contribute.

##### 2.1.2.4 Psychological aspects of the abuser relevant to design

Much of psychology literature on the archetype of the abuser attempt to profile personality traits that define an abuser through questionnaires, but come to varying conclusions as to the best working theory - whether there is a 'typology' of abusers, or just congruent traits.

For example, Rode et al (2015) determines in their study of a mixed-gender (46.3/53.7% in favour of men) sample of 227 persons aged 19-67 that both the sample and its gendered subgroups "do not differ from the general population" - though an earlier work of Rode's (2010) appears to group a sampled population into typologies through k-means clustering, seemingly demonstrating the difficulty of determining proper interpretation of data. Other studies such as Gadd and Corr (2017) take the idea that typologies are insufficient, but that personality traits that are risk factors for abuse can still be considered. Regardless of discourse, consideration of relevant traits may be useful in assessment of risk likelihood and impact; however this is something best assessed on an individual basis, with associated 'abuser factors' influencing direction of analysis rather than end result.

In terms of psychological *theory*, one literature review on theories of violence (King 2012) notes that one approach to understanding the psychology of the abuser is the usage of *implicit theory*, built upon a 'pathological belief system' (see Walker & Bright 2009) obtained through childhood experience (see Polaschek et al., 2009). Through reading Polaschek et al.'s work, King identifies potentially relevant theories as to why offenders may use violence:

1. Through an environment where violence is the norm, offenders view the act as a tool to be used as means to an end (as may have been used against them or their peers).
2. Violence is a necessary deterrent and tool to thrive in a world built upon it; either to dominate ("Self-Enhancement") or to protect ("Self-Preservation").
3. The offender may use violence as a means of authority, either "in the service of others or to maintain the social order".
4. The offender may view themselves as 'forced' to use violence or otherwise unable to regulate violent impulses.

Much of King's review focuses on 'violent criminals' rather than domestic abusers, which encompasses a wider range of violence and necessarily implicates a bias of the underlying sources towards *physical* abuse (since physical harm is easier to prosecute and make criminals of than mental harm); however, in the context of this project where we use this information to undertake threat modeling, the adversary is primarily viewed in context of harms realizable (of *any* type), to which awareness of the 'belief system' of an adversary might assist as an indicator of 'approach'.

An *adversary-centric* approach to threat modeling - as described by Cohen, J. (2019) - is atypical to the standard 'attack-surface' based model, but given prior research on the general sociological and legal issues surrounding DV it can be assumed that by default, most victims have a large 'attack surface' that they cannot do much about without wider societal change (and by extension, neither can the DMS in consideration of design). Thus, consideration of adversarial 'axioms', as Cohen describes in another article (2019), might be better leveraged; with an initial focus on the scenario-specifics *supplemented* by 'good practice', rather than the inverse.

Typically, security threat modeling of adversaries assumes the scope of organizations or political agents that may act with some predicatability; this might seem irrational to apply to something as emotional as abuse, but *coercive control theory* (Stark 2009) seems to indicate that this idea of 'intellectualizing the abuser' may hold some weight. Even despite this, the field of security is no stranger to modeling adversaries with incomplete information, and to accomodate for the unpredictability of the abuser typical concepts such as reducing 'attack surface' and 'protecting assets' may be used to cover the victim when the abuser does not appear to act according to predictable adversary models.

##### 2.1.2.5 Strategies of the abuser relevant to design

The concept of *coercive control theory* (Stark 2009) considers many modern aspects of abuse to be premeditated and malevolent in nature from the perspective of needing to enforce previously 'hard' power asymmetries into softer projections thereof through methods of control instead. Though primarily constructed through the lens of feminist theory (and so once more, perhaps unrepresentative of abuse in LGBTQ+ couples), Stark also notes its origination from comparison of 50s' domestic violence with those in nonfamilial situations, such as "hostages, [POWs], inmates, mental patients and [cult members]", including the tactics used thereof.

According to Stark, this intentionality occurs as a result of modern sensibilities making abuse covert; in societies with egalitarian values, abuse must be personal and direct, but undetectable by external parties; and thus we might consider that the contemporary abuser is schooled - consciously or otherwise - in tactics of violence from those with power, experience, and monopoly - such as (in some incarnations): the state, corporation, church, or dictator. This may affect our design on the basis that - adjusted for scale and context - the abuser might be modelled as a form of *Advanced Persistent Threat* (APT), meaning our tool must fit into the associated paradigms of security, both digitally (internally to the integity of the DMS and its environment) and physically (in terms of its usage as part of a wider strategy and any risk considerations its use brings).

###### 2.1.2.5.1 Economic Abuse

Economic abuse appears to be a concept only recently defined as separate from general physical and psychological abuse. Historically, the primary tool used for measuring the problem in an individual appears to have been the Scale of Economic Abuse (SEA), as defined by Adams et al. (2008). However due to the wide range of questions in the original SEA, it appears to have been modified in studies that reference it for studies on economic abuse, such as Postmus et al. (2012); the initial issues perceived by researchers is further defined by a literature review on the subject internationally, also by Postmus et al. (2020), which indicates a large majority of studies seem to have used a variety of methods. Only five studies appeared to use the SEA or its modified equivalent, SEA-12 - the latter developed by Postmus et al. (2016) - and many appear to have instead used tools for measuring *Intimate Partner Violence* (IPV) that simply include items of economic abuse.

The original SEA's constructs *have been validated* (Adams et al., 2015), and so perhaps this is simply the result of a lack of prior effective tools for measuring economic abuse; the constructs of economic abuse - that being *Economic Exploitation, Control* and *Employment Sabotage*, the latter added by Postmus et al (2012) - appear to be used by 14 of the papers sampled according to the review, so the work appears to carry weight taxonomically at least. The constructs themselves can be generally described as follows:

| Construct | Type of Abuse | Example item - Postmus et al. (2012) |
| :-------: | :------------ | :----------------------------------- |
| *Economic Exploitation* | Use of victim's reserved finances without their consent in a way that worsens their financial situation. | "Spend the money you needed for rent or other bills." |
| *Economic Control* | Aggressive collection/withholding of financial intelligence from the victim. | "Demand to how how money was spent"; "Keep financial information from you." |
| *Employment Sabotage* | Actions that prevent the victim's financial independence through means of paid labor. | "Do things to keep you from going to your job" |

In the same year, Adams et al (2020) created a revised scale in the form of SEA2; it reduces the number of items - a key issue raised in Postmus et al (2012) - and revises the phrasing of *Economic Control* to *Economic Restriction*, perhaps to better encapsulate the concept of 'employment sabotage' as defined by Postmus et al (2012). It has less (59) citations as of time of writing compared to SEA'1' (657), but appears to build upon that work, and so may see increasing use in future studies.

In the concept of our design, the primary concern is the use of constructs in terms of its use in threat modeling and the impact of economic abuse on deployment of the tool. It is considered that perhaps the DMS concept cannot be applied readily to mitigate what is known as 'Employment Sabotage' by Postmus et al. (2012), although it does have undeniable impact on efficacy (if purchase of technology is required for deployment).

Perhaps more worthy of consideration in this context are *Economic Control/Restriction* and *Exploitation*, which focuses on the capacity for the abuser to remove finances from the victim; the abuser can only remove currency and prohibt paid activities that they can see directly or via outcome, and so use of the DMS to protect communications channels with persons outside of the abuser's remit - for example, to exchange cash, cryptocurrency, or to use a bank account the abuser is unaware of - may be a significant need. As a result of this, the potential for economic abuse must also be considered in threat modeling and risk assessment efforts for our fictional case study.

This communications use-case is already inadvertantly supported by certain messaging platforms already - such as Whatsapp (2023) and Signal (2023) - but they may be restricted to certain countries or (in the case of the latter) cryptocurrencies that cause friction, and the abuser may already be aware of these methods, reducing their efficacy. As such, the DMS might be flexibly adapted to protect the security of comms channels for labor and covert exchange of currency that, by necessity, have been adapted for purpose.

###### 2.1.2.5.2 Mesosystemic Abuse

In one literature review on post-separation abuse (Spearman et al., 2023) the concept of *mesosystemic* abuse - that pertaining to community connections with the victim - is cited as one frequently used by abusers.

Tactics vary, and for various ends: destruction of connections with the victim is a strategy used to facilitate social and physical isolation - later discussed in section 2.1.2.4.5 - and in some instances mutual connections are leveraged in order to keep the victim within reach. Socially powerful abusers may make localized use of negative campaigning tactics such as smearing and social undermining that affect the victim's ability to not only remain safe, but to even attempt to thrive.

Rarely does an abuser operate alone in such cases, as others are often 'recruited' for the cause, be they aware of the abuser's nature or not - often an asymmetry in levels of trust and closeness between the abuser and victim from the recruitee's perspective can be a deciding factor, and allows for the abuser to have further reach beyond what they can themselves achieve; a person might not believe a statement from the abuser themselves, but a rumour spread with several degrees of separation and spoken by a person more 'trustworthy' might be believed readily on first exposure. From the project perspective, it might be considered that such coordination of persons for the purposes of abuse could be a form of 'organized' abuse - and so perhaps tactics applicable to 'large scale' abuses of power, such  systemic abuse, might also be somewhat applicable within mesosystems, as indicated before with parallels to negative campaigning.

Spearman et al. also mentions how technology (expanded upon in section 2.1.2.4.3) can remove typical 'walls' the victim can put up against the abuser, such as moving to another city or country; communications can "overcome geographical boundaries" and can cause the shadow of an abuser to follow the victim, even when they themselves are not present. A particularly insidious and outwardly-adjusted actor may even take these measures while the victim is still in the abusive relationship in order to dispel the idea that they can 'escape' their situation at all.

Given the potential for use of communications technology to provide support to the abused when nobody local will (see Craig and McInroy 2014), the consideration of mesosystemic factors that may contribute to destruction of these systems should be a risk that accounted for in threat modeling at minimum, though the ability to implement complete countermeasures via the DMS design alone may be debatable.

###### 2.1.2.5.3 Technology-Facilitated Domestic Abuse (TFDA)

TFDA primarily refers to the leverage of existing communications, location and networking infrastructure that allows an abuser to extend their 'reach' beyond the 'tangible world' - that of finances, physicality and localized mesosystems. One review by Afrouz (2023) shows that perpretrators have a wide variety of tools at their disposal. For the purposes of simplification, tools and methods available to the abuser can be categorized in terms of usecase; Intelligence/Surveillance (Tracking apps/spyware; 'cyberstalking' of profiles - both via old/reused credentals, 'publically accessible' means and parental controls; and use of *Open-Source Intelligence* - or OSINT - tools), Harassment (Contact via media platforms, phonecall/text spam and other means of harassment of the victim and mesosystem) and Coercion (threatening to reveal intimate photos/videos online, or using tech to covertly capture compromising material).

In the same review it appears that many aspects of mesosystemic abuse and coercion are present as extensions of their use in non-technological contexts; harassment is conducted over social media and through other users, whereas coercion is performed in the context of - for example - threatening to release intimate content, or threats of revealing Personally Identifiable Information (PII); an action colloquially known as 'doxing'. For the purposes of harm through harassment and coercion, technology augments existing 'offline' methods by allowing them to grow in reach and consequence.

In addition, the abuser need not rely on the mesosystem or offline apparatus to gather intelligence, as these methods can leave a trace that can alert the victim to their presence; through the use of anonymization tools, social media and *open-source intelligence* (OSINT) tools and techniques, a determined or skilled adversary can obtain information and query it using modern data analysis techniques, all while remaining anonymous or psuedonymous. For this reason, TFDA appears to be difficult for police to prosecute for, based on lack of evidence (see George and Harris, 2014). 

To properly model TFDA-based threats to the victim however, defining abuser capability in terms of *competence* and *access* rather - as Freed et al (2018) does - is more useful; the vast majority of abusers have a limit to their technical capabilities, being 'UI-bound' - but *do* often have 'ownership-based access' through being a device provider, and can compromise credentials by coercing the victim or attempting to 'brute force' into accounts. Effectively, in cybersecurity terminology, they are an 'authenticated adversary' - with the 'insider threat' being the most similar organizational equivalent. On this basis from a design context it might be best to assume the victim's computing environment as a 'low-trust' one, and design accordingly.

Perhaps because of its more invisible nature, Afrouz notes that in contrast to what is typically ascribed for dealing with online harassment - just 'logging off' or removing one's presence online - many victims tend to keep in contact with abusers; having a consistent line of communication means that they can more accurately assess mood and actions and prepare accordingly (effectively, a form of counterintelligence). Simply 'cutting off' the abuser is difficult in an online context as (like in the real world) they can simply relay information or contact through the mesosystem. Due to the hyperconnectivity the internet provides, the victim may perhaps have to isolate themselves more deeply in the digital world than the physical world (see Section 2.1.2.4.5) to achieve the same effect of safety - something that assists the abuser in establishing the feeling of 'omnipresence' (as used by Afrouz) over the victim, remotely affecting their mental state.

It should not, however, be assumed that in a context where the abuser can 'only' use TFDA (for example, in the context of *post-separation abuse*) that their capacity for harm is purely over the digital medium; existing legal, state and organizational apparatus can be used in combination with intelligence to enact harm, and with enough recent PII collected on the victim, the abuser can make moves to once again establish *physical* presence in the victim's life, allowing for typical methods of *Intimate Partner Violence* (IPV) to occur. Sometimes the abuser does not even have to carry the stick themselves; in the adjacent context of cyberbullying often law enforcement is leveraged via actions such as 'swatting' (making a fake call and pretending that an incident requiring armed response is occurring at the victim's address) being a problem frequently faced by people that are 'digitally public', such as influencers (Jaffe 2016).

TFDA tends to escalate after separation, becoming the primary means of abuse according to Afrouz, and often abusers partaking in TFDA are more technologically savvy than their victims, to the point where some lacking in technical skills struggled with identification of TFDA (see Freed et al., 2017). This extends to those that might potentially help, as Afrouz also identifies; some frontline workers assisting in mitigting TFDA are lead to give advice without significant enough confidence on how best to address the issue (see Freed et al., 2018). The legal system appears to lack enough knowledge of the issue to know how to make such law applicable, and in some cases this has made prosecution difficult (see Henry et al., 2020).

The underlying conclusion, then, is that the victim's protection against TFDA in the current year is a mostly personal process; a fact shown by Afrouz (see Zaidi et al., 2015), referencing a study of female technical competency relating to its impact in TFDA, wherein Zaidi et al. states that 40% of the participants noted a move to learn about technology following TFDA out of need for empowerment.

In the interim while understanding around TFDA and subsequent effective legal and service-based countermeasures improve, victims ultimately require familiarity with aspects of personal privacy and security, much like the civil servant, banker, or officer/soldier that inherently become targets for abuse and attack based on role and responsibility. To expect the victim to do this entirely alone at great cost (and perhaps without requisite social connections) would be unfair however, and so resources (see Bazzell 2023) and specialist services exist that can assist with this. However this implicitly excludes persons of a lower socioeconomic background that might not be able to afford the costs of such measures; in line with *coercive control theory*, we might also assume that countermeasures used by the victims of 'organized' abuse (such as those in oppressive regimes or crisis situations) might have some level of applicability, alongside other vulnerable persons; such resources are free and readily accessible, such as those provided by the *Electronic Frontier Foundation* (2023).

###### 2.1.2.5.4 Social and Physical Isolation

Isolation of the victim from the rest of the world (both in a physical and social sense) can generally worsen outcomes. Rural areas of the world are frequently the subject of study within DV literature, and factors (Loxton et al., 2003) such as general lack of access to resources, needing to keep 'good faith' with the community that provides what little is available and the comparative great expense of leaving the abusive relationship contribute greatly to the issue. It can be seen that being suffering from DV in a rural area amplifies all components that prevent *anyone* from exiting the relationship, such as (as previously stated) distrust in law enforcement due to the 'small world' nature of rural communities, and that the mesosystem (being all-encompassing or 'everyone-knows-everyone' in such cases) is easily reachable and manipulable by the abuser, leading to a desire not to 'rock the boat' that extends beyond immediately involved parties (Kirshnan et al., 2001).

The issues of isolation are not entirely mitigated by existence within areas of high-population density either, however, and if anything it appears as though rural communities merely inadvertantly optimise for social isolation and abuser control of the mesosystem, rather than cause it exclusively; Bornstein et al. (2006) show in their qualitative study of LBT (Lesbian, Bisexual & Trans) communities within Seattle that this issue propagates even within large metropolitan areas, and the same issues are raised by respondants in interviews as have been noted by Loxton et al. and Kirshnan et al., such as issues surrounding pre-existing community bias and stigma; one respondant in Bornstein et al. (2006) is quoted as saying that "[Gay people] just don't want to hear [about the abuse]".

It might be considered that the commonality between social isolation in both rural and queer communities might be that the communities are, themselves, isolated also; rural communities are isolated by years of history and current decisions to remain so, and queer communities are isolated by historical need of protection of one another from wider society, and so it might be further *assumed* that this is a significant risk factor for being a DV victim in the first place (vulnerable people come together on commonality of need, and in some cases, we must refer to the idea that 'hurt people hurt people' - see section 2.1.2.2.1).

However it should be noted that vulnerable people also likely *need* close-knit support networks to be well - Craig and Mcinroy (2014) identify that for LGBTQ+ people growing up in areas that are intolerant of the demographic (in some cases, like aforementioned rural communities), having a separate, supportive online community is a crucial factor in healthy establishment of identity during childhood. Through similarity of oppressive control - the DV victim against speaking out and the queer child against coming out; effectively disruption of the 'peace' - we might consider that perhaps the same concept of a supporting external community applies to *any* vulnerable individual in an environment hostile to their existence.

In terms of applicability to the project, it might be assumed that an external support community is *required* for a DV victim to go through the process of leaving an abusive relationship, be it within the same physical locality or not; given that the DMS - being a digital system - has better knowledge of digital environments than external (analogue) ones, it could be effectively applied in ensuring that the digital mesosystem is not poisoned by the physical one - that the 'outside world' does not enter the victim's safe space.

In essence, then, the issue of isolation in the context of DV can be effectively connected to unwilling particiption in a hostile mesosystem, and that under coercive control theory, *isolation* is an end goal of the abuser, achieved through manipulation of the mesosystem (see section 2.1.2.4.2) - and so in common security parlance, we might consider the 'mesosystem' to be an *asset* the victim wishes to protect from an *adversary* (the abuser) to prevent the impacts of *isolation* (thought to be of high *likelihood* through our review so far).

##### 2.1.2.6 Psychological aspects of the victim relevant to design

In using Stark's theory on coercive control (2009) to model the means and tactics of the abuser, we might also consider that as the 'enemy' of the abuser, the aware DV victim might also share some parallels to enemies of power; and thus might be empowered by the tactics and theories of subversive elements. However we must also note the wide range of motives and aims of typical subversives; while all subversives wish to have the detail of their movements hidden, some wish for outomes too significant to hide. Indeed for some, the visibility is the endgoal - but assuming the same applies for the victim is a dangerous fallacy, as the knowledge of active subversion by the abuser is likely to enrage them into harsh punishment.

In addition, discovery of the victim's movements and tools therein might make their support network vulnerable, if the abuser acts as part of a structure - such as where the role of abuser is societally ingrained - meaning that ideally, by the time the abuser (presumably) inevitably discovers the actions or movements of a victim working to free themselves, they are out of harm's reach and unchasable. In this sense a victim that has to take matters partially or fully into their own hands (a scenario all too common, as illustrated prior) shares more in common in terms of threat modelling with the journalist and spy, being subversive actors that must also protect their confidants; thus consideration of concepts of tradecraft in identification of victim psychology and countermeasures may be an important design consideration.

Finding distinct psychological markers that act as a risk marker for suffering DV is difficult due to the mentally transformative nature of victimization; however Pereira et al. (2020) notes that suffers of abuse during childhood are more likely to suffer from abusive relationships in adult life also, drawing upon the previously discussed concept of *intergenerational violence* (see section 2.1.2.2.1).

Further leveraging this idea is a recent umbrella review (Hogg et al., 2023) supporting the theory of comorbidity between traumatic childhood experiences and later mental disorder, and another questionnaire-based, cross-sectional study (Gupta et al., 2023) indicating that *Intimate Partner Violence* (IPV) amongst persons suffering from psychiatric disorder is common (though importantly, this is a risk factor more for victimization than perpretration).

It should also be noted that study on a german populace (Clemens et al., 2023) indicates a significant overlap between perpetrator and victimization roles - sometimes with the reporter having been both at different points - and notes that this likelihood of combination is directly proportional to age, and inversely proportional to household income. However the greatest indicator for *both* victimization and perpetration amongst subjects for *all types of abuse* (but especially physical) were *Adverse Childhood Experiences* (ACEs), perhaps suggesting that this overlap is one more relating to childhood trauma than psychiatric disorder (even though the former impacts the latter as established by Hogg et al).

What we can somewhat theorize given the above studies is that the victim and abuser might share some aspects of psychology through shared background. The full extent of these and their accuracy seems sparse in academic literature, but from an operational security perspective (which by necessity involves consideration of operator psychology) we might consider that both victim and abuser might share some of the *'cruel world hypothesis'* as established by *implicit theory*; see Section 2.1.2.4, King (2012).

Specifically, we can perhaps assume that some subsets of 'pre-separation' victims follow the application of Polaschek et al. (2009)'s 'pathological belief system' against themselves - one where the tenets of the beliefs act as maladaptive rationalization of their situation. This idea might apply only in some contexts, like those where abuse is a culturally accepted fact of life - see section 2.1.2.2.2, Guracho and Bifftu (2018) - review of academic literature suggests that this idea of 'learned helplessness' might manifest for different reasons in societies where abuse is maligned - notably, the context where Stark (2009)'s *coercive control theory* applies. Childhood abuse might be an appropriate proxy for cultural acceptance (given that it implicates a violent norm in 'the family'), but this is an entirely separate topic of research in itself.

From a design perspective these models of victim psychology inform our knowledge surrounding the 'operator' in our security model, perhaps whether we should be careful to prevent misuse of the DMS to 'reflect abuse' back onto the intial abuser, or whether we operate on the assumption that the victim might be prone to OPSEC failure due to psychological factors, or similar considerations.

##### 2.1.2.7 Strategic countermeasures of the victim relevant to design

###### 2.1.2.7.1 Coping Mechanisms

**Note: some of this needs to be refactored out of this section into other parts.**

Research on how psychological theory around coping works has been argued to apply differently to contexts of domestic violence as defined by Waldrop & Resick (2004). Conceptually they note that coping has been categorized by various criteria; whether the coping mechanism is *approachful* (for example, talking about the issue) or *avoidant* (i.e., denial of the situation) in nature, and whether the mechanism itself is *cognitive* (changing how you think) or *behavioural* (actions taken to reduce stress). The two also indicate that coping behaviours may be defined by constraints in one's situation, and so use this amongst a lack of sampling of domestic violence victims as a basis on which to call for further research.

At this point it should be noted that some coping mechanisms the victim may employ might be incompatible with the proactive use that the DMS would require; in particular, those using *avoidant* coping mechanims might be unsuitable candidates for its use; in the timeline of abuse from pre-separation, to mid-separation to post-separation, it would be considered that those with avoidant coping mechanisms are likely to potentially be suffering from pre-separation abuse, and so are in a position where sociological, psychological and communitarian efforts would be primarily effective in helping the victim realize their ability to break out of circumstance (something which the DMS can assist with).

Unfortunately, avoidant coping mechanisms might be utilised by quite a large proportion of the population; persons with maladaptive cognitive schemas ('frameworks' for interpreting experience) tend to be associated with *avoidant* ('disengagement') coping mechanisms according to Calvete et al. (2007)'s study of a sample of 298 battered women; in their overview of the literature they also note that although cognitive schemas are difficult to change, traumatic experiences *can* disrupt pre-existing ones, and put maladaptive schemas in their place. The subsequent conclusion is, then, that perhaps the archetypes commonplace in abuse relationships (those traumatically affected, both in past and present) might be mostly in that 'pre-separation' state, and so they require human assistance over technological aid (see section 2.1.2.7.X).

However we should note that even though the use of a DMS might not be fully applicable to pre-separation abuse, the nature of abuse can mean that progress can backslide, and a 'separation in progress' can be brought back by the abuser; we should thus take note of what kinds of coping mechanisms are specific to DV as a concept, so that we can assess their relevance when threat modelling. It is perhaps not incorrect to model that the victim themselves might sometimes pose risks to themselves due to the abuser's psychological manipulations, and we may need to consider this fact in the employment of security strategy to a situation.

For a more low-level perspective on what coping mechanisms are used, Lempert (1996) notes a few patterns amongst a self-selected sample of 32 female survivors, derived from in-depth interviews that consisted of open-ended questions to allow narratives to be delivered in the interviewee's words. Lempert uses the term "invisibility phase" in reference to attempting to hide the abuse, from the public and the self; this can be likened to the 'pre-separation' concept of abuse in our own terminology.

Lempert derives some potentially relevant insights; some survivors appeared to have altered their behaviour to 'keep the peace' and avoid negative definitions (such as insults or slurs relating to promiscuity, laziness, or homeliness). This inevitably could not match as abuse escalated, and ensuing cognitive dissonance provided distress. Face-saving strategies were employed to maintain the "invisibility phase"; and, Lempert theorizes, to maintain a sense of self - by leaving the problem unspoken (and themselves 'unvictimized'), the problem becomes 'non-existent' and therefore unreal (in essence, an advanced form of *avoidant* coping).

Some survivors also took the simultaneous belief that only *they* could help themselves, yet were powerless to do so. Perhaps in this sense technological aids like the DMS might be able to provide a sense of empowerment without making the unknown 'known'; leveraging concepts like anonymity and psuedonymity might provide enough of a 'protective barrier' to people in this phase of abuse to more easily break their cognitive distortions.

Despite all this, Lempert notes that in the studies, there appears to be a noted 'progression' in stratagem, going from preservation of the relationship (*avoidant* coping, denial) to *analysis* of why they were abused and its effect on their selves (approachful, *cognitive* coping), followed by attempts to prevent it from occurring again (approachful, *behavioural* coping), and an overarching realisation that the problem was a *social* (and not *personal*) one.

Within this, then, the narrative is constructed that DV victims going from 'pre-separation' to 'mid-separation' are not passive *or* powerless - indeed, Lempert warns against this as disempowering - and so it might be considered that the movement from a 'pre-separation' ("invisible") state to a 'mid-separation' ("visible", open) state of play is one that the victim reaches themselves.

Though the DMS might not be able to operate in the capacity of 'ensuring communications' here, it could be applied to *assist* the victim in a way that will never 'kiss and tell'; its usage in this context *should* be explicitly as a tool for use, observation and benefit of the victim *alone*, by their definition. Perhaps technology, in this sense, can help the victim along the 'assistance pipeline' where humans and services cannot, much like a journal or first aid kit might - the victim has complete autonomy over it, and so can trust it wholly. Such cases by necessity empower the victim by assuming they are the authority on the accuracy of their own 'threat model', and perhaps this assumption of 'engineer knows best' is what prevents current technological aids from helping in all circumstances.

###### 2.1.2.7.2 Formal services and assistance

Many services for domestic violence assistance appear to be of grassroots origin, such as shelters, hotlines, and counseling and advocacy services. This can make evaluation of their efficacy somewhat complex, as one study on the topic across 87 state-funded Illinois-based agencies (Bennett et al., 2004) notes, having to instead create new outcome measures in their own evaluation due to the ineffiacy of existing solutions. Bennett et al's findings were that funding for shelters generally produces positive results based on endorsement of key outcome statements by eligible participants, but the limitations of such findings are severe due to the context of this being the first statewide evaluation as such; data was self-reported, had no control group and were collected by providers (not the researchers), meaning random sampling/selection was not employed. The subsequent image painted is that determining the efficacy of shelters as a strategy for victims is difficult via typical data analysis.

Perhaps services and advocacy are more useful in terms of their ability to make victims aware of the circumstances of their situation and progress out of the "invisibility" phase by daring to make the issue visible (and so destigmatized) themselves. As seen in previous sections (2.1.2.3) and by a review by Øverlien & Holt (2019), the invisibility issue of DV makes it hard for the likes of law enforcement and the justice system to operate effectively with victims in a way that recognises their circumstance. Øverlien & Holt also raise a necessity that the victim be a significant part of the process by having their voice be heard, so that the - at that time current - limited understanding of research on 'the victim experience' can be improved; something they note has been critiqued as something limiting effective intervention (see Edleson, 1999).

However it should be noted that sometimes advocacy and services backfire for the victim, as noted by McDermott and Garofalo (2004); in previous sections (2.1.2.3.2, 2.1.2.3.3) it is noted that the law and the officer are ill-equipped to handle the circumstance by having to wrestle between the idea of viewing domestic violence as a problem *society* needs to deal with, or one that the victim must - although assisted - handle themselves; the former approach being one that strips victim autonomy (as previously discussed in Section 2.1.2.3.2 and argued by Bailey, 2012). It might be thought that this does not apply to grassroots advocacy either, but McDermott and Garofalo (2004) also note one occasion in which a victim is encouraged by an advocate to refer to an incident as a beating, when they themselves by prior experience considered the usage of the term incorrect. Though the advocate may have been well-natured in this instance, in some cases their attempts to 'inform' can actually disempower victims as can be seen in this case; and perhaps expriences like these might contribute to formal support being perhaps less useful than it could be.

In addition, it should be noted that the services and types of approach that victims or survivors require differ dependant on demographic. For those not typically part of the heteronormative narrative on DV, cultural and identitarian barriers can mean that a different approach is required; for example, one study focusing on support services for Asian male DV victims (Cheung et al., 2009) suggests that feelings of shame and expected roles of masculinity are factors for a lack of self-reporting amongst male victims, and cites the importance of anonymous usage of services in such cases. A meta-analysis focusing on Same-Sex Intimate Partner Violence, or *SSIPV* (Santoniccolo et al., 2023) notes that victims in such cases often end up seeking informal sources of help over formal ones, with sources noting that the latter were often unhelpful, or had barriers to usage such as 'low awareness and knowledge of the phenomenon [of same sex DV]'. The underlying message is that formal theory cannot be universally applied to all cases, and that understanding of what is needed for demographic minorities of abuse is crucial.

If the DMS is used as a means to keep the victim 'connected' with the outside world, it might be worth consideration as to whether those connections might actually harm progress for the victim. These cannot be necessarily mitigated within the DMS, but a different context of use might be a better fit that allows shelters and other formal services to keep their niche. As indicated in Cheung et al.'s work and discussed prior, perhaps the ability of technology to provide anonymity can be a help in this regard, and the DMS can provide an anonymous 'safeguarding' system that simultaneously keeps the link from professional services present while allowing for autonomy.

###### 2.1.2.7.3 Informal communities

Sometimes, informal communities and trusted contacts are the only people that a victim feels they can disclose information to. This can cause several complications, however; Trotter and Allen (2009) note that despite social networks being a crucial part of ensuring safety and wellbeing - often being preferred *before* formal services - negative or mixed responses were unfortunately common in their study of 54 respondants. One of their resultant conclusions is that from an outside perspective is that by no means should victims have to rely solely on informal communities; though for countless reasons mentioned earlier, we can easily see that many victims *have* no other option, be it due to cultural stigma, insufficient legal systems, or shelters focused on handling common 'victim demographics' (heterosexual women) at the accidental expense of victim minorities.

In addition to this we cannot deny that from an ethical standpoint, informal supporters of a DV victim are themselves affected by hearing stories; one review by Gregory et al (2017) on related literature shows that being in a 'supportive role' for a DV victim, or being witness to tragedy as a result of another's DV situation can contribute to psychological affectations such as PTSD (alongside a general risk of suffering harms from the abuser themselves).

Given that it has been previously noted (see Section 2.1.2.6) that poor mental health is an increased risk factor for later abuse, it might be cautioned that in some sense, perhaps being a caregiver or informal helper for a DV victim might increase the risk that said helper themselves suffers from DV in future life; an aspect that implies that epidemological theory - particularly social/emotional contagion theory (see Christakis & Fowler, 2013) - might apply to the context of domestic violence too, though community violence and neighbourhood crime rates are notably *not* associated with IPV (Meyer et al., 2023). 

Despite this, Gregory et al. (2017) notes that risk factors for caregivers might be a significant reason as to why some DV victims feel they must keep silent (effectively 'quarantining' themselves from others), and their findings indicate at least some *transmission* of traits (perhaps shared trauma).

Perhaps different from typical narratives on epidemiology noted in the review is the idea that those who have experienced DV - directly or otherwise - both identify current victims more easily and feel a need to provide support for them (something the review cites - see Staub & Vollhardt, 2008 - as a 'survivor mission'); this in many ways can act as part of the healing process.

It might be considered that by modelling aspects of domestic violence in this way, that perhaps the use of certain technologies relating to maintaining social interaction during the 2020 COVID-19 pandemic might also be a useful way to consider the context in which the DMS is applied; sometimes professional, in-person assistance is required - as the shelter worker, psychologist and doctor act as psychological equivalents to physical health - and for other cases the assistance of supportive peers (with consideration to potential contagion) is useful, such as when the victim cannot access professional services.

One percieved flaw present with this modelling perspective might be the comparative ineffectuality of support services that are 'remote' rather than in-person, particularly of the informal variety, but this can be seen to be false, and indeed online communities can be used to build up the 'self' and identity in a way that might not be so accessible via official channels; Craig & McInroy (2014) notes the internet being used in this aspect for LGBTQ+ youth growing up in otherwise hostile environments, for example, but even within the context of DV there is evidence of a similar approach working there; Hurley et al (2007) note that online domestic violence support communities allow the victim to construct and observe the self through the narratives they construct - a concept known as the 'generalized other', and something that could be a significant part of the understanding process for victims in the "invisibility" or pre-separation phase of abuse. Noting the significance of this and potential reliance on digital spaces if the abuser is restricting physical freedoms of the victim, the implementation of a DMS might be useful to ensure that these support networks either stay open or allow for authorities/formal communities to become involved if the situation worsens to the point where informal communities can no longer help.

###### 2.1.2.7.4 Retaliatory, Violent and Self-Preservative Measures

Violent reprisal by DV victims, as one might expect, is often done in situations where it is perceived that there is no other option. In Walker (1989)'s work on the subject (which appears to act as an original 'starting point' of research), she observes that the typical 'case study' of a 'battered woman' (in heteronormative terminology, befitting of the time) is, importantly, one that believes only 'they' can change their situation - as previously observed in Section 2.1.2.6's study of Lempert (1996) - and that doing so is possible. 

Victims that committed homicide had partners that used violence frequently of brutal fashion that was constantly worsening over time, including death threats and commands to either kill the abuser themselves or to commit suicide. In essence, the circumstances that appear to result in homicide appearing as a viable option are the worst-case scenario for a victim, and may be representative of wider systemic failure to combat the DV issue as a whole.

Whereas in previous sections reviewing DV literature the heteronormative bias of samples used has been noted as a shortcoming, regarding homicide the physical differences in strength between those assigned male at birth and those assigned female must be noted to be an unavoidable factor in understanding the nature of such actions; most women, Walker observes, ended up utilising weapons and means of violence that mitigated or removed the physiological disadvantage that was presumably at play - 75% used firearms, though Walker writes that "in many of these cases, the woman did not choose to use a gun but shot the abuser after he threw a gun at her, in some cases ordering her to shoot him before he shot her." Some women hired contract killers to do the job on their behalf; given the circumstances, though, it might be considered that Walker only observes this high prevalence of arms usage because those that did *not* use weapons against their abuser in a crisis situation likely died during the confrontation, or failed to commit homicide.

Whether these same dynamics apply in relationships where both parties (by being assigned the same sex at birth, or otherwise being of more similar musculoskeletal frame due to early-life hormonal treatment than sexual dimorphism would typically allow) seems an area seemingly unresearched, depsite its area for use by defence or prosecution-led argumentation in a court of law; Ahumada & Milena (2012) produce the closest approximation through viewing the application of Walker's theories and the subsequent use of *Battered Woman Syndrome* (BWS) via the lens of lesbian and gay couples, but, perhaps due to lack of case law, limited research appears to exist on how this issue applies in general, and none on queer couples outside of the realm of homosexuality. Ahumada & Milena note that there are at least some 'common threads' between BWS in heterosexual and homosexual couples, but see the gendered nature of BWS as enough of a barrier to proper viewing of the issue to call for a new, neutrally-gendered approach.

Regardless of issues described prior, the undeniable power differential in Walker's demographic of abuse (male-on-female, heterosexual) means that even existing self-defence legislation can be harsh; Hubble (1997) observes in an article on this issue that in some cases, retaliation occurs in 'non-confrontational settings', such as when the abuser is asleep or otherwise not posing an active threat, falling afowl of the requirements in some legislation that 'necessity' of the homicide is *reasonably* required (terminology that is loose, but workable), alongside that the belief must also be *genuinely* held - something subjective enough that proving as such is difficult.

Some feminist writers, according to Hubble, seek to have the definition of 'necessity' of homicide be *objectively* defined by the law rather than subjectively so. Hubble (perhaps rightly) refrains from injecting opinion into his analysis, but perhaps this is a 'loosening of the belt' that acts an extension of the (as seen in Section 2.1.2.3, and again, perhaps rightful) distrust in systemic process that has lead to the homicide in the first place, and such advocacy that this is a good first step contains nihilism that legal systems can ever prevent heavily violent abuse cases from reaching this point, and that self-defence is the only option.

From the perspective of the DMS' design, at least, to accept this would be to admit that the technology itself would be entirely useless in preventing such an outcome, and that if threat of death is involved, no 'fail-deadly watchguard' can prevent the outcome in the first place; something clearly false, if its use as a 'fail-deadly' device by whistleblowers - persons that might be attacked with organizational, not personal, might (see Zetter, 2013) - is clearly seen.

It is considered, then, that (voluntary) surveillance (or proxy thereof) that involves the DMS might instill the fear of law in the murderously violent abuser once more, and prevent such outcomes - though in such cases, feminist observations (as noted by Hubble) and those of Ahumada & Milena (2012) are correct that self-defence legislation must better accomodate for victim circumstance in the event homicide of the batterer still occurs. Perhaps a better idea, instead (and observed somewhat in existing solutions by Section 2.1.2.7.5 below), is the idea of using the DMS as part of technology that aims to react to violence far before stakes reach homicidal levels, as in such instances the relative 'coolness' of such situations might be necessary buffer to compensate for the inability of technology alone to capture all aspects of the established complexity of ongoing DV in general.

###### 2.1.2.7.5 Technological Countermeasures

It is known that TFDA (See section 2.1.2.5.3) is easily facilitated by abusers, and that it has affects the victim's ability to use technology itself - under high levels of risk and stress, they struggle to identify UI details, privacy/security features, and acting upon instructions, as noted by Slupska & Tanczer (2021). Quite a few DV victims, then - particularly those after the 'physical control' phase and in the 'escape' and 'life apart' phases of IPV as defined by Matthews et al (2017) and later adapted by Slupska & Tanczer (2021) - appear to disconnect from use of technology, at least in Matthews et al (2017)'s sample; In less extreme cases by deleting accounts and having less of an online presence, but in more severe cases by destroying devices, or removing internal components (such as batteries and SD cards) and hiding them on their person.

Such measures appear to be fuelled by fear and low technical expertise; Freed et al (2018) notes in their study that the establishment of abuser 'omnipresence' (through spyware) resulted in what the authors refer to as belief in the abuser being "magical" (to disambiguate, having the perceived untracable/undefinable ability of the abuser to find them). Cybersecurity experts familiar with threat modelling might consider such countermeasures as excessive in all threat models except for state-targeted whistleblowers, but rather than dismiss this as paranoia, a common thread is identfiable between the (perceived) threat model of the unexpertised IPV victim and (actual model of) the whistleblower on-the-run; that being lack of knowledge regarding adversarial 'reach' (what can the adversary compromise), meaning they must fall back to 'undeniable truths' based on expertise. One that works for both would be 'broken technology is unusable', for example.

Thankfully, for the victim's threat model, more measured responses can be made based on data that allows awareness of the abuser as a profilable adversary; given what Freed et al (2018) notes about the average abuser (see Section 2.1.2.5.3), a useful proxy for a 'secure' system in the context of TFDA might be defined as to whether someone can 'compromise' assets only using UI-based tools or services. This is not a high bar to reach by any means; most organizational efforts focus on securing against career criminals and state actors (Advanced Persistent Threats, or APTs) rather than UI-bound attackers who might, usefully, be considered archetypically similar to 'script kiddies' (the latter being a colloquialism present in hacker and cybersecurity language that pejoratively refers to persons - often juvenile - that lack the ability to write their own exploits).

Knowing this adversary archetype allows us to create a more measured threat model, which is crucial for re-establishing trust in technology for the victim as a tool of empowerment that allows for things such as helplines, legal assistance, and a life away from the abuser, and that thus, a safe life is very much possible through good cybersecurity practice alone. Unfortunately, this means that the 'big guns' of technological solutions aren't needed, and indeed likely increase the risk of abuser misuse more than they assist the post-separation victim - though a DMS could be useful for alerting during automated counterintelligence efforts against the abuser, such as evaluating whether the abuser might be able to discover a new location.

Perhaps a more applicable context where a DMS can assist is by allowing for secure use of computers in an *ongoing* abusive relationship, and indeed this appears to be where many solutions in the space focus; one review (Kouzani 2023) notes the prevalence of machine-learning driven violence detection systems, both applied to signs of real-world violence via cameras, microphones and ambient sensors, and to digital communications through sentiment analysis; alongside uses of anti-stalking technologies to detect tracking devices, spyware, keyloggers and hidden cameras.

Other technologies, such as those that are already enjoyed in a general sense for enhanced security (such as password managers and 2-factor authentication) and those used for rehabilitation of abusers (such as virtual reality) are also mentioned, but Kouzani concludes that AI-based solutions for detecting ongoing abuse (digital and physical) appear to be the most effective as of current, and are often used *in conjunction* with other solutions, technical and otherwise; though Kouzani also warns that "the limited availability of large datasets poses a risk in accurate predictions [that reduce accuracy in combination with dataset and/or algorithmic biases]". Combining metrics from the likes of ambient sensors, communications and smartphones, then, might allow for a 'normalisation' of error in such a case.

Though Kouzani's work establishes there is still room for technology to assist in the *pre-separation* phase of abuse where the abuser has physical control, the main problem with such solutions is that they are designed and written for a specific usecase in mind, and can rely on expensive technologies that may be inaccessible for those with little socioeconomic power (something acknowledged in the review itself). This is further excacerbated by ethical, privacy and security concerns - as previously noted by Matthews et al (2017) - that may exist in the technology, and are already latent in the victim, especially where cultural barriers exist.

Integration that makes sense for victim countermeasures thus appears difficult, because available technologies - which endpoints the victim uses, their trustworthiness - both in a cybersecurity sense and due to the impact of 'omnipresence', see as previously discussed using Freed et al (2018) - and the availability of external, supporting actors such as communities, individuals, services and the state all affect what *makes sense* to use as a solution. For example - a device that uses machine learning to detect signs of violence and contacts police will never be used by a victim that has had bad prior experiences calling them manually.

The 'concept' of the dead man's switch - detect the presence of something, or sustained lack thereof, and react accordingly - is one that is ultimately leveraged in all of these tools, and the ability to have a framework that manages most of the underlying architectural 'cruft' of handling this aspect could be useful in adapting the solution to a desired thing to detect (the 'observation' metric) and the desired reaction (the 'payload') in a way that flexibly *respects victim autonomy* might be crucial for uptake, as can be inferred by the myriad reasons for why victims do not engage with systems explored in this literature review. Each case, ultimately, is complex and requires the victim to be able to have a say in how they want to be protected from harm, within the bounds of morality and law.

### 2.2 Limitations of current research and areas for further work

#### 2.2.1 Biases of sexuality, gender and ethnicity in sample demographics for DV research

Many studies on DV victims feature a sample demographic that meet statistic majorities; studies on abusers broadly consist of males, and on victims, females; for both, heterosexuality is a norm. This to some extent cannot be escaped due to demographic statistics; these majorities are not fabricated by any means - most abusers really *are* male and most victims really *are* female - see Ghani et al. (2019), where this is stated to have at least been historically 'true' from an academic perspective - but the prevalence of male-female pairings (and thus, cisgendered, heterosexual relationships) means that the underlying theories and discussions in many of these papers may only *somewhat* apply to other demographics.

As we can see throughout the literature review (see Section 2.1.2.2.2), the forms in which domestic violence manifests and the attitudes of the victim and abuser to the situation differs based on cultural, social and legal norms; as has been shown via Vandello and Cohen (2003) and Guracho and Bifftu (2018)'s work, aspects of the *reasoning* behind why abusers abuse and victims are left trapped differ based on societal environs; Vandello and Cohen demonstrate that in societies that accept it, the abuser is afforded a 'right to control', and the victim is blamed and abuse considered a form of corrective discipline.

It is not unreasonable to assume that if reasoning behind abuse and its endurance thereof changes, so might the actions taken - or lack thereof - by both parties, alongside any such effects. Prior research in Section 2.1.2.7.2 (see Cheung et al., 2009; McDermott and Garofalo, 2004; Øverlien and Holt, 2019) indicates that viewing victim and/or survivor support inflexibly simply *does not fit* the reality, and that the circumstances surrounding the victim are varied enough - even *within* societies, nevermind *across* - that protocols, terminologies, and treatments cannot be nearly as uniformly applied as with physiological conditions.

Though the state of domestic violence literature on different cultures and societies is by no means sparse, the foundational theories of the field are built from a certain theoretical narrative; that of feminism, looking at Walker's work (who in many ways appears to be one of the pioneers of modern DV theory). The problem arises not from the application of feminist theory itself - indeed, feminism has been essential to recognition and study of the problem in the first place - but in some instances, the foundations of its thought are difficult to extend. Namely, in instances where patriarchal power dynamics do not apply *as* strongly; that being certain subsets of platonic, romantic and sexual expression in modern society, and relationships that are outside of the typical dichotomy of heterosexuality, gender, and even sexuality at all (the LGBTQ+ community). Research does exist on these edge cases (see Bornstein et al., 2006; Santoniccolo et al, 2023) but is limited by what appear to be cultural and societal barriers; these prevent deeper understanding of whether existing DV theory applies when feminist theories of power in relationships - where DV is viewed through the biases of a heteronormative, cisgender and allosexual lens - might not. The time where this research question can be answered without significant societal bias seems a long way off, and its resolution possibly depends on whether the LGBTQ+ community's values are assimilated into wider society, much like feminist theory before it.

In the context of this project, then, the resultant conclusion to make is that whatever solution is made may be based upon theory that may not apply to all demographics, and that the efficacy of the tool might be limited by the limitations of the field itself. Care should be made during the design process that the assumptions upon which decisions are made can be considered reasonably unlikely to shift with existing projections for further work in the field as discussed above, and that potential issues with accessibility and bias in the technologies used are either accounted for or noted in discussion.

#### 2.2.2 Lack of consideration of risks of tech deployment, and the prevalence of the *human element* in TFDA

Technology is servile to whoever has access to it, and access controls suffer from one key limitation; that *proxies* of the authorised person's *presence* and (unpressured) *consent* are measured. The five factors of authentication (What you *know, have or are*, *where* you are or *what* you do) show as such, and by the means of which computers measure these things - via passwords, devices and programs - they can be necessarily coerced, forged, or otherwise acquired. Abusers, being established as 'UI-bound' attackers - see section 2.1.2.5.3, Freed et al (2018) - must necessarily rely on social engineering efforts earlier than more advanced attackers might due to the ease with which a system can be viewed as 'secure' by the adversary (i.e., "I cannot exploit this via technological means").

If the abuser's ability to manipulate mesosystems (see Section 2.1.2.5.2) and mental state through action (See Section 2.1.2.5 in its entirety, though this idea is at least somewhat tautologic within the field) are any indication, it would be useful to model the average abuser as using social engineering as their primary method of attack. The attack vector exposed by people (the targets of social engineering) is a significant one - Verizon's *Data Breach Investigations Report* (2023) indicates that 74% of their breaches $(n=4,482)$ were at least partially contributed to by *some human element*, so it can be seen that a particularly determined abuser might have more reach than initially thought.

On top of this, it might be theorized (importantly, this is not measured in the dataset) that most of the persons in Verizon's sample were of a better mental state than a victim would be as a user on basis of demographic normalisation; it has been documented - see Section 2.1.2.7.5, Slupska & Tanczer (2021) - that at least under the DV context, victims, being under high levels of stress and risk, struggle to use systems. It might thus be a logical next step to conclude that in the personal context, victims as a demographic might be especially susceptible to some forms of social engineering (such as coercion or emotional manipulation), and more likely to accidentally commit an error - aspects that lead to breaches.

The reason as to which all of this is noted is that technological countermeasures for DV appear to sidestep this challenge, if recent reviews - see section 2.1.2.7.5, Kouzani (2023) - are interpreted correctly; risks of technological misuse by the abuser and issues of privacy and safety are acknowledged, but consideration as to how the 'human element' plays into this cannot be seen. The typical cybersecurity dichotomy is also one of protecting the 'user' from the 'system', and makes the assumption that the system itself is *less* problematic (perhaps because system security is more controllable); but due to the complex requirements of the victim, the rigid, to-spec production of a secure system could be in fact *harmful* to the user if it results in outcomes that make their situation worse.

To provide an example; several of the solutions reviewed by Kouzani (2023) use machine learning to detect signs of violence and react accordingly, necessarily implying the setup - and *obscurement of* - a technological device with sensors as part of deployment by the victim. Noting that machine learning systems have been prone to bias in the past (Navarro et al., 2021), and that the 'reaction' such a system must produce (intervention) necessarily alerts the abuser to its presence, the fact that such a system faces issues surrounding correct activation need be explored; they cannot detect nuance (indeed, even outside persons get it wrong), sentiment of the victim (do they want interventionist assistance *right now*) or even evaluation of whether the victim's sentiment regarding intervention is *worth consideration* - it is a reasonable assumption that both victims and abusers, being participants in a scenario fuelled by emotion, are not always rational actors or thinkers and that sometimes, following a victim's wishes could result in more harm than violating said wishes - meaning that in some instances the 'triggering' of the system could be considered the semantic equivalent of throwing oil on a fire to try and starve the flame of oxygen.

Perhaps such thinking is unproductive in consideration of how technology can assist the victim against an abuser, being preemptively dismissive of the help it can provide, but this seems to be the attitude that some victims - rightly - might have against new technologies due to the sheer prevalence of TFDA (See sections 2.1.2.5.3, 2.1.2.7.5); thus this aspect must be considered heavily in regards to how it might affect the nature of Human-Computer Interactions (HCI) with any solutions and the implications on *both* system security and personal security (to whit, how the users affect the system and how the system affects the users in turn). Slupka and Tanczer (2021) note the difficulty of implementing migitative strategies for TFDA due to design choices benefitting both victim and perpetrator, and identify the current limitations of cybersecurity applied to IPV due to its origination from organizational contexts (militaries and businesses), calling for influence from IPV researchers regarding the research and development of digital countermeasures to allow the adaptation of existing cybersecurity theory to accomodate for the uniqueness of IPV as an issue; evidently, there are many classical assumptions in security that simply do not apply in the same way in a DV context, and must be recreated or adapted.

In the subsequent context of the design of the DMS and its cybersecurity considerations, the primary useful constructs that exist are those relating to the modelling of the adversary and the victim; both are generally technologically unskilled, utilise aspects of OPSEC and various forms of espionage and OSINT to compensate via manipulation, destruction, and creation of the mesosystem and life resources, and the abuser can - and *should* - be considered to meet the adversarial model of the 'insider threat'. The technological rigidity of such solutions and their potential to 'misfire', 'aim off-target' or 'overreact' as a result of their inherent power to affect should also be a prime consideration when building the DMS as a solution; in many aspects due to its potential for misuse, the technological DV countermeasure can be considered to be a weapon - a tool that projects force ultimately indiscriminate in function - and should be designed with such a visualization in mind.

Slupska and Tanczer (2021) demonstrate a system-based approach in their discussion of challenges, consisting of designing the **system**, identifying *threats* that can be realised with it, evaluating a **response** to said threats and subsequent **validation** of analysis in an example of creating a smart lock; similar works in this space seem scarce, and so referring to their work during the design process as a sound basis on which to create secure systems that are considerate of nuances in IPV appears paramount.

#### 2.2.3 Inconsistency and inaccessibility of documentation on uses of the DMS concept in general

Terminiology surrounding the use of the 'Dead Man's Switch' (as in, the concept that we have demonstrated through example and described earlier in this report) is contested, and various terms are used interchangably to mean many different things, all of which could be considered some form of 'Dead Man's Switch', in the context of detecting proxies of human incapacitation. To demonstrate the sheer scope of this problem of like terms, a table is presented:

| Field(s)/Context(s) | Term(s) | Functionality Described |
| :-----------: | :-----: | :---------------------- |
| Public Transport, Power Tools | "Dead Man's Switch/Handle", "Deadman's" | Continually 'activated' device that triggers fail-safe mechanisms on release, acting as a proxy for driver incapacitation. |
| Public Transport | "Vigilance Device", "Dead Man's Vigilance Device" (Wikipedia, 2023), "Sifa/*Sicherheitsfahrschaltung*" (German train systems), "Driver Safety Device" (British Railways trains), "Driver Vigilance Device" | As above, but with additional requirement to occasionally release and re-apply the switch. Implemented to prevent false-negative scenarios where driver is incapacitated but keeps the DMS held; see the *Waterfall train disaster* (Wikipedia, 2023). |
| Cybersecurity, Espionage, Military | "Dead Man's Switch" | 'fail-deadly' system that requires continual 'resets' from an authenticated individual to prevent its triggering. Used to either protect a system from inspection if the user is caught or to act as a form of defensive blackmail ("if you do X, Y will happen.") |
| Cybersecurity, Vehicular Safety | "Kill-cord" | Adjacent to a 'kill-switch' (device that triggers fail-safe when activated), but through implementation (cord, rope etc., attached to operator) implies use in detecting operator incapacitation through removal from the seat. In the context of cybersecurity such devices are used to prevent against being suddenly removed from a device containing sensitive work. In vehicles, they are used to detect 'man overboard' scenarios (e.g., falling off a speedboat). |
| Computer/Systems Engineering | "Watchdog timer", "Watchdog", "Heartbeat", "Fault detection" | Thread or subroutine that confirms health/liveness of system-critical processes, similar to the 'Dead Man's Switch' in cybersecurity. Often used to allow safe handling of hardware failure, such as input devices. Logically, may be used in some safety systems as part of 'defence-in-depth' against failure of the DMS (operator-facing) system itself. |

Within the review of existing Dead Man's Switch literature the effort has thus been made to describe these systems in terms of how the concept of 'protecting against operator or system incapacitation' can be implemented in different ways. The inclusion of watchdog-type systems that do not *directly* monitor input or a device connected to the operator can be argued to fall outside of this definition, but in earlier sections (2.1.1.1.4, 2.1.1.1.5) the counterargument is made that at a certain level of system complexity, the typical 'dead man's switch' cannot be effectively implemented without also implementing verification of the underlying health of the components that make up said switch; particularly in computing usecases (which remain somewhat unexplored), the 'inputs' that make up a dead man's switch may indeed be components used in normal operation of the device, and so they are symbiotic in nature.

Finding academic-quality resources on the design - and even **existence** - of DMS systems is also difficult, due to their nature of implementation as part of complex commercial systems and devices that have information obscured and abstracted via design documents (customer-facing, operator-facing, and internal) and trade secrets.

To demonstrate how this issue manifests - one *rumoured* example of a DMS system for which primary sources of its existence were untracable was within the *Bombardier Incentro AT6/5* low-floor trams commonly used by *Nottingham Express Transit* (NET), which supposedly used a capacitive touch sensor-based vigilance device, according to the Wikipedia article on Dead Man's Switches (2023) which - despite the general inadvisability of reliance upon the service at an academic level - has at times been resorted to as a last-hope guideline for which fields, areas, works, projects, events and even authors should be referenced and searched using Google Scholar in an attempt to find descriptions and examples of their design and use suitable for academic citation. Wikipedia's statement of DMS systems being present on NET trams itself is riddled with requests for citation within the page itself; trying to find official, properly citable documents from NET or Bombardier on the spec of the *Incentro AT6/5* as a primary source proved impossible, and going about directly contacting Bombardier or NET for this information would likely be unfruitful due to NDAs, and so this example **cannot be confidently stated as factual** (despite the apparent usefulness of being able to access resources regarding a vehicle in active use in the city NTU is located). This was by no means the only example where a historical or current implementation of the DMS had to be left undiscussed on basis of hearsay and inferential evidence being all that was accessible.

Often during review, descriptions of historical DMS systems were only *rarely* findable through archival services such as *The Wayback Machine*, and with incomplete bibliographic information; furthermore, many times actual documentation was hidden in books with citations that provided insufficient information on the actual chapter or page(s), meaning requesting interlibrary loans through input forms was effectively impossible. The examples shown in the review are those thankfully crafted as a result of scientific articles and papers produced by persons aiming to implement, document or evaluate the DMS concept within specific contexts, alongside instances where Health & Safety standards authorities have mandated their inclusion in tools and products (necessitating a description of the specific implementation deemed acceptable).

To summarise, because of the DMS' *apparent* (unconfirmed) inception within company-manufactured transport, such as the Birney Safety Car, according to Wikipedia (2023) - subsequently see the primary source of Young (1997), the existence of which has been confirmed, but the book itself unsourced and thus unreviewed - there is an apparent 'black hole' present in the literature on Dead Man's Switches that requires extensive review, research and discovery efforts beyond the scope of what this report can provide, and so it is quite possible that analysis on the details (and thus flaws) of prior DMS implementations is incomplete.

#### 2.2.4 Replicability of DV research

Though on basis of frequency of research in certain aspects of DV, criminological and psychological literature can be considered reasonably accurate due to similar findings by other studies, the nature of how participants in many studies were sourced - victims were volunteers, abusers were incarcerated, studies on officers relating to prevalence of DV were sampled from specific police departments in specific countries - belies a sense of unease regarding the ability to replicate findings and conclusions.

Some samples - like the convenience sample of police officers in Blumenstein (2009)'s study of whether officers were likely to commit abuse - are fundamentally difficult to replicate because of the sheer specifity of the population surveyed; a specific U.S. state - Tampa, Florida - of self-volunteering officers only within departments that had a survey distribution mechanism *at the time of research* - implying handling of the surveys by the departments themselves (a potentially biased party) and a constantly changing variable of *which departments had a survey distribution mechanism* - indicate that even if Blumenstein's conclusions are correct, it may be quite some time before the study can undergo an attempt at replication (and perhaps replication of this specific sampling method is inadvisable). Blumenstein herself even notes the problematic nature of this sampling methodology in the discussion section of the paper itself.

Even in contexts where established DV theory is present, the ever-shifting nature of abuse is problematic for *future* replication of underlying theory in pioneering work. The influence that culture, society, law, the economy, the mesosystem - *the world at large* - has on how it is seen, perpetuated, mitigated and escaped is a factor that cannot be ignored, as has been seen throughout the review (inexhaustively, see sections 2.1.2.2, 2.1.2.3, 2.1.2.5.1 and 2.1.2.5.2). Theories and models for DV must therefore be constantly evolving and changing, as does the world. Some aspects of abuse will stay the same - physical violence will never *not be considered abusive* by the field, for example - but how those aspects are *conveyed* by abusers and victims alike will change both with resources they gain and lose, as well as with awareness or lack thereof by the mesosystem, populace and state. Examples of this are already apparent throughout the review - Stark (2009)'s *coercive control theory* would simple have no reason to be followed by an abuser in a society where abuse is simply *accepted* or even *encouraged*, and indeed Stark mentions that aspects of coercive control theory only appear within societies that outwardly condemn abuse.

Similarly, Vandello and Cohen (2003)'s observation of domestic violence as a means to 'regain honor' amongst men, and Guracho and Bifftu (2018)'s observation of 'right to discipline' in Ethiopian instances of DV do not appear to apply in societies where masculine honour and typical gender roles are downplayed. Evidently, these gendered observations are not the sole reasons for abuse, due to its occurence in same-sex relationships (where heterosexual gender roles - at least at first glance - might not apply); the essence of abuser and victim psychology for same-sex relationships might be the same, but what *influences* these myriad aspects in *what way* and to *what extent* is a research question seemingly impossible to engineer study conditions for.

The issues the field faces in this regard can be directly seen in how it affects the usefulness of services for persons outside of the historical norm for domestic abuse samples, such as men, and the LGBTQ+ community. Presenting theories for how this might be rectified is a problem outside of the scope of this report, and the replication crisis has been a heavily documented and discussed issue in the sciences; but this aspect in many ways affects the ability of technical solutions to scale in complexity, as the more complex a system the more inflexible it is to being configured for specific requirements of the scenario.

#### 2.2.5 Lack of studies for determining efficacy of technological countermeasures to DV

In terms of theoretical, *technical* efficacy, Kouzani (2023) notes in their review the relative efficacy of technical measures, and as stated before, notes levels of accuracy for various machine learning models; values are high (In many cases > 90%, and on at least one trained model an accuracy rating of 100% is stated), but this still doesn't help to assess the efficacy of these models *in context of use;* Does using solutions - such as machine learning algorithms to detect signs of verbal abuse over social media - actually *improve* outcomes for DV victims, or not? Such a question is difficult to answer due to the aforementioned (section 2.2.4) malleability of the DV issue to the ever-changing nature of surrounding environs - there are quite simply too many variables to assess this in a statistical manner with any kind of reliability, and so hueristic, feedback-based methods of evaluation must be used to compensate as a result.

Due to the sensitive nature of DV as a field, also, sampling of victims and abusers in a way that accurately represents the reality is difficult; the majority of studies on victims appear to be on those that are in the 'post-separation' phase of abuse - or even completely free from their former abuser's continued presence at all - by the nature of accounts and questionnaire responses being framed in the historical tense. Attempting to include persons currently suffering abuse, or those not entirely safe is something that transgresses boundaries of ethics and morality, as by nature of participation in the study they may be put at increased risk. As a result, then, the field in general has an issue with a lack of documentation on what works during the pre-separation phase of abuse due to inability to survey victims, meaning that evaluating what works for people *currently being abused*, particularly solutions that exist within the area of abuse, such as the technological innovations outlined in Kouzani's review (that monitor for signs of violence, both visually and aurally).

Due to the strong ability for technology to affect a situation, perhaps calling for better sampling of efficacy in the pre-separation context for evaluating solutions is unreasonable, and instead evaluating the strength of a design based on the completeness of DV-specific security analysis as has been recommended and exemplified by Slupska and Tanczer (2021) is a useful measure as of current. In the interim, DV research struggles to focus on the problem of getting a victim 'out' of the pre-separation phase due to these barriers, and it is suggested at this point that looking into ethical ways of sampling such a demographic might be a worthwhile venture not just for the field of DV, but for many other fields as well to evaluate the efficacy of their own suggestions to assist with the problem.

#### 2.2.6 Inherent inflexibility of theoretical frameworks, and solutions based upon them, against requirements for victim autonomy

In some ways, there is a clash between the validity of the victim as a source of 'truth' about what is being felt and identified and the need for medical authority in relation to the issue of DV. For the victim, there is the inherent possibility of avoidant coping mechanisms (see Section 2.1.2.7.1) alongside 'rationalization' of abuse at the cultural and societal level (see Section 2.1.2.2.2) which can mean that in some cases the victim is treated similarly to someone who cannot fully rationalize the need for their own care, and so medical diagnosis must be referred back to - this is a somewhat outdated notion, but might still influence some aspects of application of theory, especially in relation to pre-separation abuse scenarios where the victim is still trapped and thus has little comfort except to cope with the circumstances until an opporunity for change presents itself.

What falters is the assumption in some aspects of theory and care that victims are still in that area of needing their experiences labelled for them by DV support workers and similar at the point where they seek to engage with formal services and professional help - see section 2.1.2.7.2, McDermott and Garofalo (2004); in this instance it can be at least reasonably assumed that the victim is aware that what they are going through is something that is not their fault and can be escaped, and so autonomy of the victim to have their conclusions about past events in this phase should be subject to some form of deference by those supporting them.

Perhaps less obvious is the need for victim autonomy even within the pre-separation phase; not just for identification of what is happening to them, but to also properly identify what services and forms of assistance would help or hinder their specific situation; unfortunately abusive situations do not follow a formula and so in respect to handling a sensitive situation, the victim is the 'expert' in identifying what measures would worsen their situation and which would help. In regards to services, theories, models and tools that help victims obtain resources, prevent incidents and generally begin an escape from their situation, they *should* reasonably defer to the victim's judgement of danger - if the victim does not want an intervention that would worsen the situation from their perspective, then ethically this should be respected unless a confident argument can be made that not intervening would lead to an outcome more dangerous than the norm for the victim (such as death or hospitalisation). Pragmatically, assessing this in the moment is difficult and mistakes will be made, but the spirit of approach is still encouragable and may lead to preferable outcomes. Other fields such as the study of aggression and physiology might be able to provide helpful insight and guidance for crisis workers that could potentially find themselves using technical solutions that detect violence to determine whether an intervention is necessary.

In regards to solutions, Kouzani (2023)'s review discusses - but does not focus on - victim autonomy of how the systems proposed are leveraged, or how they are implemented, or what things they are willing to allow to be monitored and what they wish to keep private, given that they have been fully educated on how the information they provide could be used in both a supporting and adversarial manner. All technical solutions produced for an issue as sensitive as DV must respect such aspects regardless, but the level of trust a victim must put into a technical solution pre-separation is far greater than that of the *post-separation* victim; whereas the post separation victim can at worst be put in the position where they must relocate, change jobs, or otherwise uproot their life in the event the abuser catches up to them, the pre-separation victim risks life-changing or terminal harms, both of a physical and psychological nature due to still being within the 'abuser's domain'.

In addition, removal of technology that violates trust might generally be considered easier for the post-separation victim, as they are already operating from an area where they both have the mindset and ability to distrust technology and not be self-reliant upon it; the pre-separation victim, while they might also not trust technology due to TFDA's prevalance at all stages of abuse, is significantly more reliant on the tools they *do* have to trust (voluntarily or otherwise) due to the inherent 'visibility' of ditching untrusted devices (not answering texts, no longer recieving location updates, etc.) and likely economic controls that limit procurement of expensive goods and countermeasures. Thus it can be seen that technical solutions for DV victims must empower victim autonomy as much as possible, given they may be forced to have little choice in what technologies they can afford to use, both from a fiscal and security perspective.

#### 2.2.7 Lack of research into methods to 'rebuild' victim trust in support systems and technologies

The lack of victim trust in technologies, services and their environment is one that has been consistently documented throughout this literature review's sections; dependant on situation, some victims, psychologically-speaking, cannot place trust in family (2.1.2.2.1), society (2.1.2.2.2), justice (2.1.2.3.1, 2.1.2.3.2), responders (2.1.2.3.3), their communities (2.1.2.5.2, 2.1.2.7.3), support services (2.1.2.7.2), technology (2.1.2.7.5), or even - in the best case scenario for the abuser - themselves (2.1.2.7.1, in the context of *avoidant* coping). Whether the distrust is well-placed or not is not the focus of this section; in some cases that facet of the problem has been discussed extensively prior, and in others commentary has been spared on tacit admittance of having to limit the scope of research surrounding the complex psychological, sociological and legal minutiae that lead to some phenomena observed.

What can be noted without author expertise on the subject is that the problem of trust appears to be a big one in the field, and not one that has any universal solution; for some areas mentioned, a solution is certainly not within the scope of what academics can influence alone, requiring attention and compassion regarding the problem from authorities in law, the courts, welfare, and the state. Roads to 'one-and-done' solutions are nonexistent; next steps are based on incomplete information ever changing in veracity, and long-term improvements the product of generational effort. In the short term, areas and studies that interface directly with victims have far more effect, simply by listening to and documenting victim experiences - the voices of many a participant in the samples used are crucial to construction of underlying arguments to push for the changes needed in society at large to continually shine light on the issue and reduce its prevalence, publically and in the privacy of homes.

Perhaps where more obvious changes can be made are within the scope of technology itself, as it has a lot to answer for in the context of TFDA. The assumption can reasonably be made that for some victims, technology *is an adversary unto itself* - it is riskier to use it compared to the benefits it can bring, in some instances. The reliance of society on technology makes this calculation of risk that victims must constantly make a hidden one, as some aspects of technology are so thoroughly intertwined with societal participation that they fundamentally cannot be avoided (inexhaustively; banking, health & medicine, welfare and procurement of goods). Things like an e-mail, address and phone number are mandatory for some services at minimum.

Technical countermeasures to the issue of DV must thus consider this aspect when 'selling' their usefulness to victims, and the best way this can be done from the start is by considering every potential angle of misuse; what data is collected and what inferences can be derived from them? How can sensors be used to gather information that might be used by an abuser? How can - if at all - the system protect against access by a credentialed adversary, or access by the victim in a state of coercion? The kind of information that can be gathered from a device depends not only on the context of its use, but any potential 'chatter' from the device in an idle state; sometimes mere knowledge that a device is on from questioning - i.e., "what is this device on my network? Why is this plug in use?" and other such questions - can be enough for a pre-separation victim to be especially harassed.

It is recalled from prior readings (section 2.1.2.2.2, 2.1.2.4) that despite earlier mention of "intellectualizing the abuser" via *coercive control theory* to try and build counteractive stratagem, the abuser *can* act irrationally with impunity - due to lack of consequence - and so even suspicion of 'foul play' (from the abuser's perspective) is dangerous. Thus, the designer of the technical DV countermeasure must be transparent with the victim not only in expressing any attack surface, as mentioned prior, but in design and, importantly, *form*; what does the device do, what are its dimensions and appearance; how are inputs collected and processed; for *what purpose/output*, and the *generalised* security implications of any implementation details and countermeasures taken. Bluntly, the pre-separation victim is the expert on their own threat model and so researchers and engineers can only claim what is *best practice*; what is effectively being proposed here is a non-technical portrayal of the methodology Slupska and Tanczer (2021) has put forth, as has been cited frequently throughout discussion of current limitations.

#### 2.2.8 Lack of research into solutions identifying the need for 'covert' support of the victim in pre-separation stages of abuse

As has been touched upon in section 2.2.7, there is an implicit sidestepping of the issue of *accomodating the victim's threat model* in the production of solutions. A frequent criticism thought of when reading about the solutions reviewed in Afrouz (2023)'s work was along the lines of "how do you propose these systems are deployed in an environment that is hostile to the victim, and seeks out and punishes subversive action?" Many systems in place assumed the use of a camera or microphone, and while there are no end of 'spy devices' on the market, these frequently are limited in battery size, and quality of sensors/recording due to 'footprint' constraints.

Because this factor appears to have been left unconsidered, it is uncertain how the computer vision or voice transcription models listed in Afrouz's review work with photo or video from small-sensored cameras that struggle to see in low-light conditions, or with microphones that might not be very good at capturing clear enough sound to prevent false positives. In addition to this only certain types of microphones may be suitable for use in covert devices, due to the power requirements for a device that might stay in a hidden position for long periods of time. The need for cabling of devices - for power, and networking - is also a consideration that might require obscurement from an abuser, and one apparently not often considered.

Thankfully, models of architectural design present in the IoT industry can help with producing effective solutions; the pre-separation victim's environment is one considered insecure and thus untrusted, and perhaps to some extent the external services they access, if the victim directly authenticates to them (see section 2.1.2.8.2) and so can be coerced by the abuser. However in terms of physical, endpoint-based security, external servers and services ('the cloud') are mostly ironclad against a UI-bound attacker; the subsequent architectural narrative made visible is that devices within the victim's domain might benefit from being treated similarly to devices that would be present in 'fog' or 'edge' computing architectures. The focus of the IoT industry in these regards is mainly one of optimizing latency, throughput, and power consumption, but the consideration of these 'zones' - the fog, the edge and the cloud - in the security-centric context of 'trust zones' might be an appreciable framework upon which to limit the attack surface the abuser can exploit.

Even considering that the context of IoT work and the threat model of the victim have a lot in common - shared requirement for low-power devices, problems with endpoint security, a progressive lack of 'environmental control' as things stray further from heavily secured, connected datacenters, and a primary usecase of 'collecting input' - it is crucial to note that above all else, having *covert* implementations (both in terms of any devices implanted, and the nature of any processing or result thereof) is more important for the victim than typical metrics of efficacy. If a device fails to record an incident that occurs, this can be bad (and reduces victim trust in the system), but if the incident is along the expected norm for what the victim suffers on a day-to-day basis, there may be other opportunities. If the device is reliable, but not covert, an angered retaliation to any kind of 'surveillance' of the abuser could prove dangerous.

Since covert, embedded surveillance devices are the favoured technologies of classified industries, finding current, open-access research on much of this might prove difficult or even impossible. Despite this, modelling aspects of the victim's situation as similar to those of an agent (scaled down for a less funded, less skilled, one-man adversary) seems to be a useful direction for further work; Stark (2009)'s *coercive control theory* creates the implict idea of the victim as the subversive, as has been touched upon in section 2.1.2.6, and so long as his theory holds weight, so too might a similar model; researching historical aspects of both state and civilian surveillance (even that used by the abuser) might show insights as to where typically 'organizational' or 'bigger actor' methods of assistance might be helpfully inversed to assist the victim (who will be more aligned with 'underdog' types, such as investigative journalists and other vulnerable persons).

## 3 New Ideas
<!--
Propose a NEW method, technique, algorithm or system to eliminate or reduce existing limitations.
-->
### 3.1 Creation of a flexible DMS system to allow for robustness to changes in environment and context

The literature review on current DMS systems shows that in all cases, a bespoke implementation is provided that is specified exactly to purpose. Rationale for this is easily apparent in many cases, as they deal with physical and embedded systems that are unique in nature; libraries for creating DMS systems are apparently minimal due to a combination of factors; in commercial systems, including those that are pre-computation, differences in design of the systems the DMS is intended to work with shapes its development - the systems are implemented first and the DMS after, which partly might be considered unavoidable for complex projects.

In the space where hardware and software intersect on equal terms, however - such as in the Internet of Things (IoT), or in industrial systems - standardized protocols and hardware seems to be default, as we see standardized microcontrollers in play due to the low-specificity of requirements in some cases. There is already evidence to show that embedded systems can be built around software protocols such as MQTT when there is room to play with implementation like this, and so it might be thought that the same could apply to the DMS concept; implementation of a functional DMS in software is not itself difficult (if-then constructs and while loops do exactly this, in the *absolute* loosest sense), but doing so in a way that (in terms of the fundamental trigger -> reaction procedure) is *robust*, *secure* and *flexible* to new inputs and outputs, and can be deployed in varying contexts appears to be something not done before to any significant extent.

In the more rigid context of the trigger scenario for a DMS being representative of incapacitation of a human operator, various implementations of sofware-based Dead Man's Switches are present (Altfield, M., 2023; Kescher, J., 2023; Haoda, W., 2023; Walker, A., 2023; hephaesto0s (pseud.), 2023; Tails Development Team (pseud.), 2023), though this has typically been within varying contexts of antiforensics and 'track-covering' activities in a cybersecurity context, or as a hobby project.

Of note is that all of these are written for a specific use-case, be it to monitor processes, the insertion or removal of an unknown USB device, or whether an SMS message is left unreceived, despite the aforementioned hardware design limitations being loosened significantly in a general computing environment, which might allow for some sort of homogenization of implementation and thus allow for larger amounts of trust (within the scope of what well-written, well-reviewed computer software can mitigate against). Why this might not have been done is difficult to ascertain, due to the variety of reasons for their development; hobbyists might simply have not wanted to take their projects in that direction, while persons who needed high assurance might have found themselves writing their dead man's switches independently to ensure trustworthiness, assuming their own competence (and thus, we cannot cite them as sources). In the further context of antiforensics, current software DMSs take a coercive stance by projecting a cost to incapacitation by 'threat of dire consequence' - a symptom of the restrictive threat models such persons self-operate under.

There is clearly a gap in the area of DMS systems in availability and assured quality; producing and configuring one requires significant technical competence at minimum, and they are often written as one-off, fit-for-purpose (but not retrofittable) solutions. This is problematic from several angles; persons who might benefit from the protection of a DMS but are not minded towards software development and security must find analogue alternatives, which are even costlier to set up, maintain, and ensure robustness, for one. Systems themselves (due to their bespoke nature) are not modular in the slightest, meaning that consistencies between all permutations of a DMS (as said before, the trigger -> reaction procedure and securing against its subversion) are not leveraged to the extent that they should be. DMS use cases vary wildly by their very nature, but the cost of 'change' in this instance can be made cheaper in terms of time and security by modularizing constituent parts and ensuring their individual soundnesss and robustness.

#### 3.1.1 Breaking the DMS concept down into modular components to allow for retrofittability

#### 3.1.2 Ensuring the security of any given component of the DMS

#### 3.1.3 Ensuring the security of inter-component signalling

### 3.2 Providing a technical solution for safe usage of victim devices that is usable regardless of ability

Even in the context of technical professionals, the best security tools are those designed to be as difficult to use incorrectly as possible. the solutions provided by Kouzani (2023) in many instances imply some capacity for configuration by the victim, something that seems inherently exclusionary towards some demographics of victims that - for whatever reason - might struggle with such tasks. Although it might be understood amongst cybersecurity professionals that removing a USB stick or doing a 'hard shutdown' on a device is typical protocol, conveying these ideas to people not well-versed in the mechanics of how computers work is an unreasonable expectation - systems that do not behave according to user expectation or understanding are not good security products, since they widen the attack surface of the human element by introducing room for error.

Abstractions allowable by current technology such as facial recognition systems facilitate the extension of human-computer-interfaces to meet the *user's* natural faculties of communication, rather than requiring that the user meet the system halfway. In the context of safe computer usage this, at face value, can only be a good thing - anything that prevents undesired usage of the system according to requirements helps reduce the possibility of 'tool failure' - where the falliability of the system compromises operations, often to a heavy extent. The concept of compartmentization is thrown about quite significantly within the context of operations, information and communications security (abbreviated OPSEC, INFOSEC and COMSEC respectively) as collorary to this; tool failure is viewed as an inevitability and the consequences dire, so risk is reduced by limiting how many assets are protected by one countermeasure. Such concepts originate in military and intelligence work and have gradually transferred to the playbooks of subversive actors; the underyling line is that no solution produced can be wholly protective of the victim, and that sadly for a victim at high enough risk, works that have adapted this theory to help civilians such as the Electronic Frontier Foundation's *threat modelling resources* (2023) are arguably unavoidable required reading.

On the part of developers of security solutions, then, the best that can be done is design of the system around a *specific* threat model, and outlining *what* the solution *cannot* protect against by scope. Examples of this exist thoroughly across many products, such as ProtonVPN (2023), Whonix (2023) and Tails (2023). Unfortunately most documentation of threat models assume the line of illegality, which is unapplicable to a victim of DV in the cases outlined by Stark (2009)'s *coercive control theory* - such adversarial behaviours only tend to manifest in contexts where the abuser *lacks impunity* due to the illegality of their actions and so must conceal the violence; the victim should - in theory - have the advantage of being supported by the system here (though in practice this doesn't always work, as covered in our literature review see sections 2.1.2.3 and 2.1.2.4). In addition, their documentation assumes familiarity with the technology and security literature by method of phrasing - these things need to be abstracted in the direction of perhaps being *over* cautious to be helpful to less technically-inclined demographics.

Tools such as facial recognition and other computer vision-based technologies can reduce the possibility for human factor-based failure. This is at the cost of increased risk of tool failure, but assuming an adversary that is not technical (*unlike* the adversaries modelled by our previous examples) means that tool failure is perhaps not quite *as* catastrophic. Failure of a tool within this threat model should be complete and fail-safe for the victim at minimum; but the *size of failure* required for a non-technical abuser to realise what is going on is far larger than the threat models proposed by other tools (which model against adversaries of activists and journalists - namely the state and political opponents).

Using computer vision tools, we can use more understandable and immediate signs of the victim's safe use of the computing device no longer being assurred that don't require intentionality in input from the user - signs such as not looking at the screen, body language that suggests interruption, or even the presence of another being in the room can all provide signs to 'shut down' that can be used when the victim is caught unawares.

The decision to use the DMS concept as a form of endpoint security over the initial idea discussed in the PPD ('alerting' confidants if the victim has not used the device/been in contact in a while) has been reached as a result of becoming more informed about the nature of issues victims face; although maintaining contact and control over the mesosystem is a crucial matter in fighting against DV, for pre-separation victims especially (those support services tend to reach the *least*) autonomy has been established as a heavy need in order to allow victims trying to escape to begin subversive action on *their own terms* - the initial decision to leverage the support of the mesosystem and/or contacts was made upon the assumption that in order to help the victim, they themselves necessarily *had to pass trust to someone outside of the abuser's immediate influence* (much like support services assume in their capacity to help) in a way that severely limits freedom of discretion; it is this issue of discretion that limits adoption of theoretically helpful services such as support shelters, the law and the justice system to those safe enough in life and mind to be candid about their victimhood, past or present. Providing options to victims in this manner can help close the gap between pre-separation and ongoing/post separation phases of recovery, as the 'leap of faith' required to cross that gap currently appears to be a significant factor. The concept of the DMS and other security/privacy based tooling can be one of many supportive options that the pre-separation victim can engage - and, importantly, *disengage* - with as their threat model requires.

#### 3.3 Establishing threat model of the proposed solution

##### 3.3.1 Case Study

In establishing this case study, several fictional characters will be created. Naming conventions will be adopted from the fields of cybersecurity and cryptography (see Wikipedia, 2023) in line with Slupska and Tanczer (2021)'s recommendations for the fields of sociology and security to collaborate regarding technical countermeasures to DV.

Given the origin of these naming conventions in evaluating the security of cryptosystems, current usage of such archetypes intentionally focus more on the *role* of each participant to fit the generic requirement of secure communication, and so some elaboration is required. When a statement is made about an actor, it will be in regards to what prior review indicates is consensus around archetypical DV situations, and so it will be qualified with a relevant citation.

![](./assets/dv_case_study.jpg)

**Alice** is a victim of domestic violence in the situation this report has previously referred to as the 'pre-separation' phase, also known as the invisibility (see Lempert 1996; Øverlien & Holt, 2019) or physical control, 'beginning escape' (see Matthews et al., 2017; Sluspka and Tanczer, 2021) phase. **Mike** (`TA01`) is her abuser, and is actively using tactics of *Economic, Mesosystemic and Technological* abuse (see sections 2.1.2.5.1, 2.1.2.5.2 and 2.1.2.5.3) and has made efforts to keep her *socially and physically isolated* from peers (see section 2.1.2.5.4) through the former. Mike and Alice are in a society where domestic abuse is considered culturally and legally unacceptable, and so Stark (2009)'s *coercive control theory* can be thought to apply, and Mike **wants to keep the situation unknown to others.**

Mike has almost complete control over Alice's use of devices, having destroyed devices of hers in the past (see Matthews et al., 2017); they have a shared PC that Alice is monitored through, but Mike is a *UI-bound adversary* (see Freed et al., 2018) and so is **incapable of monitoring what Alice does outside of what is observable via a UI interface.** Mike has no objections to attempting to break into devices or accounts of Alice's and will pressure her into divlulging information about things he thinks she knows about that he doesn't. To avoid ambiguity, it is assumed that **Mike *will* eventually gain access to any account of Alice's that he knows about** (see Matthews et al., 2017). Mike historically has been more knowledgable about technology than Alice (see Afrouz 2023), and has used this leverage as control in installing tools such as spyware (see Matthews et al., 2017).

Due to Mike's pervasive control over her use of technology, Alice has had to learn quickly about its use after various incidents (see Matthews et al., 2017), with the help of a few confidants. **Bob** (`A04`) is a real-life friend that knows Alice's situation and is on her side, as Mike has had a history of doing this. **He has not reported things to police on her request, on the agreed-upon stipulation that he will break said promise if he thinks she is in severe danger** - something Alice is worried about, but ended up accepting out of a need for help. He is somewhat technically minded and so has given her an external hard drive (`A01`) with a live operating system on it, and taught her how to use it so that it can be used on the shared PC. This hard drive also contains a *secure password database* (`A02`) that she stores some credentials on. Both assets are unknown to Mike, and must stay that way - at best he would destroy the hard drive, but at worst he would gain access to the password database - and potentially put some of Alice's contacts at risk.

Through Bob's efforts, Alice has been able to regain online contact with **Wendy** (`A03`), an old friend that has known her before Mike's abusive nature started becoming apparent. Wendy has met **Chuck** (`TA02`), which concerns Alice. Chuck is a friend of Mike's, but barely knows Alice; and so Chuck likely believes whatever Mike says to him. Alice isn't sure whether Chuck and Wendy talk still, and so cannot fully trust her at the moment - despite potentially needing her help in the future to escape Mike.

Faythe (`A05`) is a volunteer counselor at a mental health support service that Alice has been trying to use covertly to better understand her situation. Alice mostly trusts Faythe socially, since she has no relation to her current mesosystem of Mike, Chuck, Wendy and Bob, but is careful about what she talks about around her in case she is legally obligated to disclose something to **Walter** or **Judy** (*the police and/or a prosecutor/judge, respectively*), or otherwise inadvertantly creates risk. There are also some nuances in the situation that Faythe doesn't fully understand (see section 2.1.2.7.2; McDermott and Garofalo 2004), and this means that conversations with Faythe are not *always* a safe space for her.

Alice's concerns regarding the involvement of Walter and Judy are less to do with treating them as adversaries but moreso as factors that would make the situation worse; Walter has shown up to the property before when a neighbour made a call, and it resulted in a later incident from Mike; Walter was unable to make an arrest at the time due to lack of criteria, and so he had to check things were alright by asking the neighbour that made the initial call (see Danis 2003). Alice is also terrified of the idea of the matter ending up in court, as she does not wish to testify about the situation to in court at this point in time. In general, she views the involvement of law enforcement and the courts to be an unacceptable outcome.

Finally, perhaps the most valued confidant Alice currently has is **David** (`A06`), an online friend she met on a pseudonymous forum where domestic violence victims and survivors talk about experiences and support one another (see Hurley et al., 2007). She can talk freely on this forum and to David without concerns of it affecting her real life too heavily, though she still feels some need to redact some information out of concern that Mike or another, unknown adversary could link her online identity to her real one. She also feels comfortable with the idea that if she ever feels unsafe interacting on the forum or with David, she can simply abandon the pseudonym - there are few other places where she feels as socially free, and so it is of great importance to her that she protects this 'online' mesosystem of hers that is free from Mike's influence (see section 2.1.2.7.3).

Given that Alice's main means of contact is via a shared device that she and Mike use - herself via the LiveOS - she wants to be absolutely sure that at minimum, Mike never knows about the password database, and at absolute best, does not know that she is using a LiveOS by catching her in the act. She has some amount of operational precautions she takes against this, but is aware they fail and would like some form of technical failsafe in place.

##### 3.3.2 Defining a threat model for Alice

Threat modelling techniques have typically existed for the securing of organizational-scale operations or projects, and so tend to focus on the idea of 'secure development' of a project. For example, The UK's *National Cyber Security Centre* (2023) provides one four-question process based upon the *Threat Modelling Manifesto* (2023) that defines objective, risk, countermeasures and evaluation. This, however, raises concerns as to whether this applies to small groups or individuals. Due to the classified nature of 'known-adversary' operations that work on this scale (such as those within intelligence and security agencies), citing organizational resources is difficult. Frequently within security and cybersecurity however, we often see presentations from former criminals ('black hats' in hacker terminology) on their methodology in a manner that is fairly battle hardened, and from a mix of this and case studies on 'OPSEC failures' we can see what works and what doesn't at the individual level. One presentation by a former darknet vendor (Bent, 2022) cites a similar 5-step methodology they used that appeared to be quite successful (based on difficulty of initial prosecution), adapted for individual work as follows:

1. What do we want to accomplish?
2. What are we building (what do we need to do it?)
3. What can go wrong?
4. What are we going to do about it?
5. Did we do a good job?

The main distinction between Bent's methodology and the NCSC's is one of objective - since the latter does not ask the question of "what do we want to accomplish", instead omitting it in favour of "what is being built". In the latter context of a secure project, the thing being built *is the objective* - whereas in the former, the construction of scaffolding is purely to facilitate the execution of the operation itself (and for no other reason). In the DV context, this order of focusing on the specifics of the end goal followed by the tools to do it is preferred, since Alice's goal is to escape Mike regardless of means. The idea, though, is that implementation of a well-designed DMS system can be a reliable countermeasure for some threat models.

The main problem with this strategy is that it is entirely focused on the idea of 'doing something or building something' and protecting operational assets alone. This type of model alone is unrealistic for Alice, since she will also have pre-existing assets that she will want to defend from Mike (such as her wellbeing, or the safety of her contacts). Thus, it will need to be combined with threat modelling procedures that focus on the *continued security of existing assets.* A threat model that considers *information security* (INFOSEC) is likely somewhat laterally applicable here, since only the means of attack and defence change against digital assets (rather than the nature of models themselves).

Given that INFOSEC is the primary concern of most IT organizations defending against cyberattacks, there are a variety of approaches to each individual component, and varying methodologies for each segment, focusing mostly on securing IT systems. Unfortunately, this means they aren't really applicable to Alice's context, and trying to retrofit them for this purpose would likely give an inaccurate model; attacks on computer systems are predictable and categorical, unlike attacks on operations or individuals or their non-informational assets. In the context of digital privacy, however, the context of 'asset-based' threat modelling for the individual has been considered by various sources (carrotcypher, 2023; Privacy Guides, 2023; Electronic Frontier Foundation, 2023), and this can be reasonably applied to any asset an individual might hold:

1. What do we want to protect?
2. Who do we want to protect it from?
3. How likely is it that we need to protect it?
4. How bad are the consequences if we fail?
5. How much trouble are we willing to go through to prevent these consequences?

It can be clearly seen that there is some amount of overlap between the steps taken to protect assets and the steps taken to protect an operation or project. Alice benefits from both models, but doing them both separately would cause an unnecessary amount of overlap and potentially overcomplicate the threat model upon which the requirements of the DMS would be considered. A 'hybrid' model for an actor that needs to operate while protecting assets unrelated to the operation can be constructed as follows:

1. What do we want to accomplish?
2. What do we need to do it?
3. What do we need to protect?
4. Who are we protecting it from and what are their motives, resources and methods?
5. What can go wrong?
6. How likely is it to happen?
7. How bad are the consequences?
8. What are we going to do about it?

Taking this 'high-level' approach to things helps construct an understanding of the situation aligned from the victim's perspective rather than an engineering perspective, and subsequently helps avoidance of unnecessary scope screep via overly-paranoid countermeasures against Alice's adversaries. In addition, it is recognised that only a subset of Alice's threat model is assisted by a technical countermeasure, and defining the entire model helps limit scope. Her threat model is subsequently defined in later sections.

###### 3.3.2.1 What does Alice want to accomplish, and what does she need to do it?

1. What does Alice want to accomplish?
   - Alice wants to escape Mike's abuse by being **physically separate from him.**
2. What does she need to do it?
   - Access to shelter/accomodation that Mike *is not aware of.*
   - Ability to travel without reliance on Mike.
   - Financial independence from Mike to afford basic amenities.
   - Trusted social contacts that can assist with the above and act as a 'collective barrier' against Mike.
   - Independent access to the internet, a trusted computing device and communications infrastructure that Mike is not aware of.
   - Separate, secure and independant credentials to services, online and offline, that Mike is not aware of.

###### 3.3.2.2 What does she need to protect that is relevant to scope?

3. What does she need to protect?
   - Knowledge of existence of the following by potential adversaries:
     - Stored finances independent from Mike (fiat/banking/etc.)
     - Means, patterns and times of travel.
     - Any shelters/safehouses she may need to use.
     - Any assets that enable her to engage with formal support (shelters/police/the law) on her own terms.
     - Any assets that enable her to communicate with others without Mike's knowledge.
   - Her continued, unknown and safe access to the internet, a computer, and means of communication, as stated in #2.
     - By extension, her continued, unknown and safe access to independant credentials to services (online and offline), as stated.
   - Her physical and mental health & safety.
   - Any autonomy she currently has under Mike, since further measures of control could make it harder to escape.
     - (Sources of autonomy not reliant on Mike's mercy are naturally preferred and obtaining and keeping them safe is more important).
   - Her contacts (from manipulation by Mike)
   - Her ability to autonomously interact with the following based on safety:
     - Formal services and the law (in regards to her situation).
     - Police officers
     - Informal systems, such as friends and online communities

It is at this point that the first set of scope restrictions can be applied, based on what a DMS system can reasonably protect against, what it cannot, and what it might jeopardize.

Protecting against adversarial knowledge can be considered as a form of data protection, and thus is better considered as part of INFOSEC. While a DMS could potentially be a physical control against unauthorized access to this information, other methods such as encryption are likely to be more effective initial countermeasures.  The DMS might be combined with these to prevent access to a *trusted device* as part of defence-in-depth, however, and so this concept of endpoint protection is the primary consideration in design. In this vein, many of the resources Alice requires to escape from Mike (social, financial, etc.) cannot be directly provided or protected by the DMS - but any indirect, digital assets that maintain access to these resources (such as credentials, communications channels and internet access) might be a fair scope in which to place the solution.

Alice's physical and mental health are not assets that the DMS can realistically protect against in entirety. What can be acknowledged is that a false positive *or* negative from the DMS may carry heavy consequences in this regard, and this will be something acknowledged in risk management. In accordance with this, Alice's current autonomy is something that is better suited to OPSEC countermeasures in how Alice goes about her escape plan rather than relying on the DMS, and is thus considered out of scope for protection by the solution.

A partial caveat to this however is the protection of Alice's contacts, both from manipulation from Mike and as a method to increase her autonomy. As noted with protection of digital resources, some requirements of the DMS might be considered under the context that this is something that Alice desires. Autonomous interaction with systems, services and the law is something the DMS can protect in the context of ensuring the possibility *cannot be taken away* from Alice, but it cannot assist her if someone has legal obligation to report on her behalf ('forced participation'). The suggested countermeasure, as described prior, would then be to advise Alice to practice OPSEC in terms of what she decides to divulge to whom; this might include whether she chooses to show her face, her surroundings or even her voice based on individual trust. Such decisions are complex and on a specific basis; no expert can advise Alice on this aspect better than herself, but *could* point out where certain bits of 'metadata' could leak (for example, her location while on a call). Regardless, this aspect of Alice's threat model is firmly out of scope for what the DMS can provide.

Because an ideal technical countermeasure Alice implements should not increase risk unneccessarily, the list might thus be categorized into what the DMS is *unlikely* to affect, what it *could* affect, and what it can explicitly *protect*.

The DMS is unlikely to affect the following:

- Whether Alice's contacts are manipulable by Mike or another adversary in the mesosystem
- Alice's ability to choose *not to interact* with contact(s) on basis of safety.

The DMS could affect the following via a *false positive:*

- Whether a given contact chooses to contact Walter and/or Judy out of concern for Alice's safety
- Her ability to access her secure computing environment, the internet, and her credentials.
- The ability to build the resources she needs to escape Mike via digital means.

The DMS could affect the following via a *false negative:*

- Her health and safety, if its failure to trigger means that Mike discovers her plans
- Alice's existing autonomy under Mike, if any.
- Access to any resources that require the use of the digital assets she has been provided.

From this outline, one reasonable assumption must be made for the deployment of the DMS to be an acceptable risk, even before a formal outline is made; **Alice accepts that the risk of losing whatever autonomy she currently has under Mike is less than the continued risks to health and safety of keeping Mike in her life.** This might seem like an obvious assumption to make, given the case study, but as established by the literature review (see Section 2.1.2.7.1, *avoidant coping mechanisms*) it is not necessarily one that applies in all domestic violence cases. This is an unfortunate limitation of the solution, and one to be discussed in depth in the relevant section.

###### 3.3.2.3 Defining Alice's Adversaries

4. Who are we protecting it from and what are their motives, resources and methods?

Alice's primary adversaries are Mike and Wendy. Wendy as an 'insider threat' is unlike the typical definition, as she does not have Alice's trusted environment; she instead has access to her mesosystem (through being a trusted contact, and potentially unknown existing connections). Mike on the other hand might not have full access to Alice's mesosystem, but has full control over any endpoint or physical asset that he is aware of, as he can coerce Alice into revealing it. Together, they present a disjointed but strong control over the safety of Alice's 'home' life and her 'social' life.

Mike's resources revolve around his majority control of Alice's *current* resources, such as travel, finances and devices. He may thus be capable of arbitrarily 'removing' resources from Alice to prevent her from achieving her goals in a way not easily counterable in the pre-separation stage of abuse, and so operating under Mike's radar is paramount for Alice. Given that from an ethical standpoint it is not expected that Alice can 'stand up' against Mike if he knows about something and acts accordingly, we model that Mike 'knowing about something' potentially jeopardizes the entire operation. From this perspective, Mike's primary motives are to maintain his existing control over her life and to *gather intelligence* about any recent changes that might limit existing controls, so that he can sabotage them.

The ways Mike can gather intelligence are primarily limited by his presumed technical expertise, where he is technically savvy but not able to 'hack'; he would be unable to perform *signals intelligence* (SIGINT), for example. Mike is likely limited to the following:

- What he can find out about her on the internet using *open-source intelligence* (OSINT)
- What he might *see* her doing, directly or via cameras using *imagery intelligence* (IMINT)
- Whatever his 'insider' (Wendy) might tell him, or what he picks up in the mesosystem, modellable as a form of *human intelligence* (HUMINT).

Wendy's motivations might simply be to spread gossip about Alice to others within the mesosystem; a partial countermeasure for this is for Alice to appear as uninteresting as possible by default as a form of cover. In terms of resources, she is quite limited in breadth; she has access to Alice's partial trust, and any shared comms lines or social connections they might have - at minimum this would be any 1-to-1 conversations they have, but could also include group chats or other 'cells' (such as if she needs both Wendy and Bob's help for something). She thus might be capable of low-skill, hueristics-based *communications intelligence* (COMINT) based on the direct contents of her conversations with Alice, or metadata thereof, including people that they both have shared knowledge of, or that Wendy knows Alice is communicating with. This could be as simple as 'reading between the lines' of what Alice says, or noting when she is online or how long she takes to see or respond to a message.

Since the DMS may directly affect Alice's access to communications based on the need to protect her operations from Mike, its triggering might provide some form of trace over this channel in the form of how it affects associated metadata, such as when she was last online, when she read a message or how long she has been inactive. To limit the amount of risks we note to those with a certain amount of relevance to the DMS, only adversarial threats relevant to the scope of what design can affect are considered, being: any traces the DMS leaves behind that may cause a risk, alongside any risks relating to Mike's discovery of her secure computing environment or any relevant COMINT that Wendy might derive from Alice being *unable* to use her computing environment due to the DMS triggering.

###### 3.2.2.4 Risks, Likelihood and Impact

5. What can go wrong?
6. How likely is it to happen?
7. How bad are the consequences?
8. What are we going to do about it?

| Risk ID | Description | Likelihood | Impact | Countermeasure |
| :-----: | :---------- | :--------- | :----- | :------------- |
| 1 | The DMS fails to automatically trigger in an instance where it should have ('false negative'). | Dependant on *reliability* of detection proxy. | High; could potentially lead to compromise of the operation. | The DMS should be implementable as part of a wider, comprehensive shutdown protocol to reduce likelihood of tool failure ('defence-in-depth'). |
| 2 | The DMS automatically triggers in a situation where it shouldn't have ('false positive'). | Dependant on *accuracy* of detection proxy in identifying the original 'trigger event'. | Medium; could potentially lead to legal intervention if a contact believes Alice is in danger if not. | The DMS should allow for Alice to configure a 'grace period' between a trigger event and the subsequent payload (shutdown) that allows for authenticated, manual override. |
| 3 | Due to a DMS trigger event, indirect legal intervention occurs against Alice's wishes, even in event of perfect functionality. | High; Alice's wishes may not necessarily be respected by legal and moral obligation. | High; Police intervention could result in Alice's assets being found out on basis of Mike figuring out 'why it happened', or a dangerous abuse incident occurring afterwards. It may also merely delay a dangerous incident rather than prevent it entirely. | Alice either chooses to communicate the existence to the DMS to few, heavily-trusted parties to prevent this, or previous 'grace-period' requirements allow for Alice to selectively interrupt the DMS if it provides more danger than safety. In the case of the former, the DMS should have a **default-disabled** means to communicate to outside parties that it has been triggered as part of the payload. |
| 4 | Wendy gains awareness of Alice's operation and reports it to Mike. | Medium if Alice contacting Wendy is not itself 'unacceptable' to Mike; Very High if it is. | Very High; Mike merely gaining awareness of the fact that Alice is operating against his wishes is enough to assume compromise of assets via coercion. | Alice must practice OPSEC and COMSEC and has to selectively evaluate the risks of a given confidant being an adversary, and must trust others **explicitly and only if absolutely necessary to operations**. The DMS should make reasonable accomodations to prevent leakage of system state and operational conditions to external entitites **by default.** |
| 5 | Faythe may be legally obligated to divulge information to authorities against Alice's wishes. | Medium; Faythe will be obliged to divulge under what conditions this must occur to Alice if she asks, and Alice can subsequently change what she communicates based on this. | Medium; legal intervention is explicitly overt, and can indicate that Alice is seeking help from a specific individual, but does *not* divulge the methods; Mike may demand that Alice stop talking to Faythe, and might enter a period of increased vigilance and paranoia for a time. | Alice practices reasonable COMSEC by restricting what information she divulges to Faythe on an ongoing basis. **Out of scope for the DMS.** |
| 6 | A malicious actor within Alice's online community realises enough information about her pattern of usage and/or life and uses this intelligence to link her pseudonym and real-world identities | Dependant on amount of metadata available to an adversary when a given Communication Event (CE) between Alice and the community occurs. | Medium; this link has to be communicated to a known real-world adversary (Wendy or Mike) in order to be significant. Potential likelihood of the impact being realised increases with time. | Alice must be aware of the metadata surrounding a given communication event and the contents of said communications. **Out of scope for the DMS.** |

###### 3.3.2.5 Evaluating requirements based on established threat model

The initial list of requirements defined in the project planning document were as follows:

|  ID | Description |
| :-: | :---------- |
| `DMS-HLR-1` | The observer component **MUST** communicate any trigger events to the payload component. |
| `DMS-HLR-2` | The DMS setup utility **MUST** operate independently from any component processes so that the tool can be set up and left to work in the background. |
| `DMS-HLR-3` | The payload component **MUST** alert other components to the outcome of an activation. |
| `DMS-HLR-4` | Any given DMS component that dies unexpectedly **MUST** show this to components that depend on it to allow for failure state handling. |
| `DV-HLR-1` | The scenario-specific observer ‘trigger prevention mechanism’ **MUST** be reasonably accessible for the victim to use in terms of availability, setup and technical ability required. |
| `DV-HLR-2` | The scenario-specific payload **MUST** provide the victim’s support network with an alert that the victim has not used the prevention mechanism. |

The original context in which `DV-HLR-2` was written was surrounding the idea that contacts within the support network are to some extent more trustworthy than the victim's internal suroundings, and prioritises this over victim autonomy in such cases. This was a naiive approach caused by the lack of knowledge, and through the literature review it is reasonable (see Sections 2.1.2.7.1, 2.1.2.7.2 and Bailey 2012) to instead derive the idea that maintenance of victim autonomy over all else is paramount to adoption of useful tools due to the low risk appetite pre-separation victims have by necessity of survival.

While it is true that some level of trust is required for Alice to receive outside support in the first place - and that the end goal is to help Alice to transition to a 'default trusted' environment - a willingness to accept some risks has been assumed, both implicitly (via the case study) and explicitly (See sections 3.3.2.2, 3.3.2.4). The working theory underlying the necessity of pre-separation technical solutions is that 'inherent trustworthiness' of services and tools alone is not acceptable at the pre-separation phase, due to the risk of unintentional harm (See sections 2.1.2.7.3, 2.1.2.7.5; 2.2.2, 2.2.7, 2.2.8), and that tools should either yield to the user or be (*accessibly*) opinionated in implementation and documentation so that the victim can easily assess risk (e.g., previous discussions of existing solutions in sections 2.1.1, 3.1 and 3.2). There is a significant gap in the 'market' of tools that *yield* to user intervention of the triggering process, and this will be a significant focus of the DMS solution provided.

In line with the above, `DV-HLR-2` is not entirely misguided, but requires rewriting in accordance with the countermeasure associated with 3. The rest of the in-scope countermeasures as defined in section 3.3.2.4 can be reasonably mapped to requirements, allowing for a new list:

|  ID | Description |
| :-: | :---------- |
| `DMS-HLR-1` | The observer component **MUST** communicate any trigger events to the payload component. |
| `DMS-HLR-2` | The DMS setup utility **MUST** operate independently from any component processes so that the tool can be set up and left to work in the background. |
| `DMS-HLR-3` | The payload component **MUST** alert other components to the outcome of an activation. |
| `DMS-HLR-4` | Any given DMS component that dies unexpectedly **MUST** show this to components that depend on it to allow for failure state handling. |
| `DMS-HLR-5` | Both *trigger* and *payload* mechanisms within the DMS **SHOULD** prefer to use existing, low-level functionality of its execution enviromment where reasonable, to limit the possibility of byzantine failure to the OS and hardware layers. |
| `DV-HLR-1` | The scenario-specific observer ‘trigger prevention mechanism’ **MUST** be reasonably accessible for the victim to use in terms of availability, setup and technical ability required. |
| `DV-HLR-2` | The scenario-specific payload **COULD** provide the **optional, default-disabled** ability to communicate its activation to outside parties within the victim’s support network. |
| `DV-HLR-3` | The DMS **SHOULD** have a configurable 'grace-period' between a trigger event and activation of the subsequent payload that allows for a manual, **authenticated** override via the 'trigger prevention mechanism'. |
| `DV-HLR-4` | The DMS and its individual components **SHOULD** make reasonable efforts to *limit the amount of metadata it produces* in both unactivated and 'triggered' states, based on forensic ability of adversaries, known and unknown. |
| `DV-HLR-5` | The *programmatic flow* of a triggered DMS in terms of the triggering 'event' and subsequent payload 'response' **SHOULD** be **reasonably abstractable** to the user in order to allow for manual replication of the process to faciliate understanding of its operation. |

##  4 Implementation & Investigation
<!--
DEVELOP AND IMPLEMENT suitable software, hardware, database or other 'tools' for testing the validity of the newly proposed ideas. This must be performed in a professional manner using the correct tools and techniques for the problem in hand.

OR

a properly conducted INVESTIGATION based on scientific principles and demonstrates the use of appropriate tools, techiques and standards.
-->

### 4.1 Design

![](./assets/Class%20Diagram.png)
![](./assets/Program%20Flow.png)
![](./assets/Sequence%20Diagram.png)
![](./assets/Use%20Case%20Diagram.png)

## 5 Results & Discussion
<!--
Use these tools to obtain RESULTS to show the quality of the new ideas. Results may be grpahs, tables or pictures that require DISCUSSION to explain their significance.
-->

## 6 Conclusions & Future Work
<!--
Summarise the project achievements as a set of CONCLUSIONS and suggest how they may lead to FUTURE WORK. Discuss the impact of **all four areas** of LSEPIs relevant to the project as implemented and for the future plans. Explain why some areas have high or low impact and how you addressed the impact in each area. You should also include a synoptic assessment in this chapter. This will comprise a reflection on the project in relation to employment aspirations and the skills developed toward this through engagement with the project.
-->

## 7 References

## 8 Bibliography
